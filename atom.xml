<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Li Yao</title>
  
  
  <link href="https://www.yaobio.com/atom.xml" rel="self"/>
  
  <link href="https://www.yaobio.com/"/>
  <updated>2025-04-23T04:03:22.948Z</updated>
  <id>https://www.yaobio.com/</id>
  
  <author>
    <name>Li Yao</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>High-resolution reconstruction of cell-type specific transcriptional regulatory processes from bulk sequencing samples</title>
    <link href="https://www.yaobio.com/publication/high-resolution-reconstruction-of-cell-type-specific-transcriptional-regulatory-processes-from-bulk-sequencing-samples/"/>
    <id>https://www.yaobio.com/publication/high-resolution-reconstruction-of-cell-type-specific-transcriptional-regulatory-processes-from-bulk-sequencing-samples/</id>
    <published>2025-04-06T14:42:06.000Z</published>
    <updated>2025-04-23T04:03:22.948Z</updated>
    
    
    
    
    <category term="publication" scheme="https://www.yaobio.com/publication/"/>
    
    
  </entry>
  
  <entry>
    <title>Comprehensive Evaluation of Diverse Massively Parallel Reporter Assays to Functionally Characterize Human Enhancers Genome-wide</title>
    <link href="https://www.yaobio.com/publication/comprehensive-evaluation-of-diverse-massively-parallel-reporter-assays-to-functionally-characterize-human-enhancers-genome-wide/"/>
    <id>https://www.yaobio.com/publication/comprehensive-evaluation-of-diverse-massively-parallel-reporter-assays-to-functionally-characterize-human-enhancers-genome-wide/</id>
    <published>2025-03-27T18:41:29.000Z</published>
    <updated>2025-04-23T04:03:22.948Z</updated>
    
    
    
    
    <category term="publication" scheme="https://www.yaobio.com/publication/"/>
    
    
  </entry>
  
  <entry>
    <title>Simultaneous measurement of intrinsic promoter and enhancer potential reveals principles of functional duality and regulatory reciprocity</title>
    <link href="https://www.yaobio.com/publication/simultaneous-measurement-of-intrinsic-promoter-and-enhancer-potential-reveals-principles-of-functional-duality-and-regulatory-reciprocity/"/>
    <id>https://www.yaobio.com/publication/simultaneous-measurement-of-intrinsic-promoter-and-enhancer-potential-reveals-principles-of-functional-duality-and-regulatory-reciprocity/</id>
    <published>2025-03-15T18:41:29.000Z</published>
    <updated>2025-04-23T04:03:22.947Z</updated>
    
    
    
    
    <category term="publication" scheme="https://www.yaobio.com/publication/"/>
    
    
  </entry>
  
  <entry>
    <title>Loss of Kmt2c or Kmt2d primes urothelium for tumorigenesis and redistributes KMT2A-menin to bivalent promoters</title>
    <link href="https://www.yaobio.com/publication/loss-of-kmt2c-or-kmt2d-primes-urothelium-for-tumorigenesis-and-redistributes-kmt2a-menin-to-bivalent-promoters/"/>
    <id>https://www.yaobio.com/publication/loss-of-kmt2c-or-kmt2d-primes-urothelium-for-tumorigenesis-and-redistributes-kmt2a-menin-to-bivalent-promoters/</id>
    <published>2025-01-13T18:41:29.000Z</published>
    <updated>2025-04-23T04:03:22.947Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Members of the KMT2C&#x2F;D-KDM6A complex are recurrently mutated in urothelial carcinoma and in histologically normal urothelium. Here, using genetically engineered mouse models, we demonstrate that Kmt2c&#x2F;d knockout in the urothelium led to impaired differentiation, augmented responses to growth and inflammatory stimuli and sensitization to oncogenic transformation by carcinogen and oncogenes. Mechanistically, KMT2D localized to active enhancers and CpG-poor promoters that preferentially regulate the urothelial lineage program and Kmt2c&#x2F;d knockout led to diminished H3K4me1, H3K27ac and nascent RNA transcription at these sites, which leads to impaired differentiation. Kmt2c&#x2F;d knockout further led to KMT2A-menin redistribution from KMT2D localized enhancers to CpG-high and bivalent promoters, resulting in derepression of signal-induced immediate early genes. Therapeutically, Kmt2c&#x2F;d knockout upregulated epidermal growth factor receptor signaling and conferred vulnerability to epidermal growth factor receptor inhibitors. Together, our data posit that functional loss of Kmt2c&#x2F;d licenses a molecular ‘field effect’ priming histologically normal urothelium for oncogenic transformation and presents therapeutic vulnerabilities.</p><h2 id="Manuscript"><a href="#Manuscript" class="headerlink" title="Manuscript"></a>Manuscript</h2><embed src="/assets/archives/2025_kmt2cd_urothelium.pdf" width="100%" height="1000" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;Members of the KMT2C&amp;#x2F;D-KDM6A complex are recurrently mutated in urothelial carcinoma and in histologically normal 
urothelium. Here, using genetically engineered mouse models, we demonstrate that Kmt2c&amp;#x2F;d knockout in the urothelium 
led to impaired differentiation, augmented responses to growth and inflammatory stimuli and sensitization to oncogenic 
transformation by carcinogen and oncogenes. Mechanistically, KMT2D localized to active enhancers and CpG-poor promoters 
that preferentially regulate the urothelial lineage program and Kmt2c&amp;#x2F;d knockout led to diminished H3K4me1, H3K27ac and 
nascent RNA transcription at these sites, which leads to impaired differentiation. Kmt2c&amp;#x2F;d knockout further led to 
KMT2A-menin redistribution from KMT2D localized enhancers to CpG-high and bivalent promoters, resulting in derepression 
of signal-induced immediate early genes. Therapeutically, Kmt2c&amp;#x2F;d knockout upregulated epidermal growth factor receptor 
signaling and conferred vulnerability to epidermal growth factor receptor inhibitors. Together, our data posit that 
functional loss of Kmt2c&amp;#x2F;d licenses a molecular ‘field effect’ priming histologically normal urothelium for oncogenic 
transformation and presents therapeutic vulnerabilities.&lt;/p&gt;</summary>
    
    
    
    <category term="publication" scheme="https://www.yaobio.com/publication/"/>
    
    
  </entry>
  
  <entry>
    <title>Finding Needles in the Haystack: Strategies for Uncovering Noncoding Regulatory Variants</title>
    <link href="https://www.yaobio.com/publication/finding-needles-in-the-haystack-strategies-for-uncovering-noncoding-regulatory-variants/"/>
    <id>https://www.yaobio.com/publication/finding-needles-in-the-haystack-strategies-for-uncovering-noncoding-regulatory-variants/</id>
    <published>2023-08-06T12:41:29.000Z</published>
    <updated>2025-04-23T04:03:22.947Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Despite accumulating evidence implicating noncoding variants in human diseases, unraveling their functionality remains a significant challenge. Systematic annotations of the regulatory landscape and the growth of sequence variant data sets have fueled the development of tools and methods to identify causal noncoding variants and evaluate their regulatory effects. Here, we review the latest advances in the field and discuss potential future research avenues to gain a more in-depth understanding of noncoding regulatory variants.</p><h2 id="Manuscript"><a href="#Manuscript" class="headerlink" title="Manuscript"></a>Manuscript</h2><embed src="/assets/archives/2023_NCV_review.pdf" width="100%" height="1000" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;Despite accumulating evidence implicating noncoding variants in human diseases, 
unraveling their functionality remains a significant challenge. Systematic annotations 
of the regulatory landscape and the growth of sequence variant data sets have fueled 
the development of tools and methods to identify causal noncoding variants and 
evaluate their regulatory effects. Here, we review the latest advances in the field 
and discuss potential future research avenues to gain a more in-depth understanding 
of noncoding regulatory variants.&lt;/p&gt;</summary>
    
    
    
    <category term="publication" scheme="https://www.yaobio.com/publication/"/>
    
    
  </entry>
  
  <entry>
    <title>Functional genomic assays to annotate enhancer-promoter interactions genome-wide</title>
    <link href="https://www.yaobio.com/publication/functional-genomic-assays-to-annotate-enhancer-promoter-interactions-genome-wide/"/>
    <id>https://www.yaobio.com/publication/functional-genomic-assays-to-annotate-enhancer-promoter-interactions-genome-wide/</id>
    <published>2022-08-26T14:08:29.000Z</published>
    <updated>2025-04-23T04:03:22.947Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Enhancers are pivotal for regulating gene transcription that occurs at promoters. Identification of the interacting enhancer–promoter pairs and understanding the mechanisms behind how they interact and how enhancers modulate transcription can provide fundamental insight into gene regulatory networks. Recently, advances in high-throughput methods in three major areas—chromosome conformation capture assay, such as Hi-C to study basic chromatin architecture, ectopic reporter experiments such as self-transcribing active regulatory region sequencing (STARR-seq) to quantify promoter and enhancer activity, and endogenous perturbations such as clustered regularly interspaced short palindromic repeat interference (CRISPRi) to identify enhancer–promoter compatibility—have further our knowledge about transcription. In this review, we will discuss the major method developments and key findings from these assays.</p><h2 id="Accepted-manuscript"><a href="#Accepted-manuscript" class="headerlink" title="Accepted manuscript"></a>Accepted manuscript</h2><embed src="/assets/archives/2022_EPI_review.pdf" width="100%" height="1000" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;Enhancers are pivotal for regulating gene transcription that occurs at promoters. 
Identification of the interacting enhancer–promoter pairs and understanding the mechanisms 
behind how they interact and how enhancers modulate transcription can provide fundamental 
insight into gene regulatory networks. Recently, advances in high-throughput methods in three 
major areas—chromosome conformation capture assay, such as Hi-C to study basic chromatin 
architecture, ectopic reporter experiments such as self-transcribing active regulatory region 
sequencing (STARR-seq) to quantify promoter and enhancer activity, and endogenous perturbations 
such as clustered regularly interspaced short palindromic repeat interference (CRISPRi) to identify 
enhancer–promoter compatibility—have further our knowledge about transcription. In this review, 
we will discuss the major method developments and key findings from these assays.&lt;/p&gt;</summary>
    
    
    
    <category term="publication" scheme="https://www.yaobio.com/publication/"/>
    
    
  </entry>
  
  <entry>
    <title>Survey of the binding preferences of RNA-binding proteins to RNA editing events</title>
    <link href="https://www.yaobio.com/publication/survey-of-the-binding-preferences-of-rna-binding-proteins-to-rna-editing-events/"/>
    <id>https://www.yaobio.com/publication/survey-of-the-binding-preferences-of-rna-binding-proteins-to-rna-editing-events/</id>
    <published>2022-08-16T14:47:18.000Z</published>
    <updated>2025-04-23T04:03:22.947Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p><strong>Background:</strong> Adenosine-to-inosine (A-to-I) editing is an important RNA posttranscriptional process related to a multitude of cellular and molecular activities. However, systematic characterizations of whether and how the events of RNA editing are associated with the binding preferences of RNA sequences to RNA-binding proteins (RBPs) are still lacking.</p><p><strong>Results:</strong> With the RNA-seq and RBP eCLIP-seq datasets from the ENCODE project, we quantitatively surveythe binding preferences of 150 RBPs to RNA editing events, followed by experimental validations. Such analyses of the RBP-associated RNA editing at nucleotide resolution and genome-wide scale shed lighton the involvement of RBPs specifically in RNA editing-related processes, such as RNA splicing, RNA secondary structures, RNA decay, and other posttranscriptional processes.</p><p><strong>Conclusions:</strong> These results highlight the relevance of RNA editing in the functions of many RBPs and therefore serve as a resource for further characterization of the functional associations between various RNA editing events and RBPs.</p><h2 id="Published-manuscript"><a href="#Published-manuscript" class="headerlink" title="Published manuscript"></a>Published manuscript</h2><embed src="/assets/archives/2022_binding_RBP.pdf" width="100%" height="1000" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;Background:&lt;/strong&gt; Adenosine-to-inosine (A-to-I) editing is an important RNA posttranscriptional process 
related to a multitude of cellular and molecular activities. However, systematic characterizations of 
whether and how the events of RNA editing are associated with the binding preferences of RNA sequences 
to RNA-binding proteins (RBPs) are still lacking.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Results:&lt;/strong&gt; With the RNA-seq and RBP eCLIP-seq datasets from the ENCODE project, we quantitatively survey
the binding preferences of 150 RBPs to RNA editing events, followed by experimental validations. 
Such analyses of the RBP-associated RNA editing at nucleotide resolution and genome-wide scale shed light
on the involvement of RBPs specifically in RNA editing-related processes, such as RNA splicing, 
RNA secondary structures, RNA decay, and other posttranscriptional processes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusions:&lt;/strong&gt; These results highlight the relevance of RNA editing in the functions of many RBPs and 
therefore serve as a resource for further characterization of the functional associations between various 
RNA editing events and RBPs.&lt;/p&gt;</summary>
    
    
    
    <category term="publication" scheme="https://www.yaobio.com/publication/"/>
    
    
  </entry>
  
  <entry>
    <title>Capped nascent RNA sequencing reveals novel therapy-responsive enhancers in prostate cancer</title>
    <link href="https://www.yaobio.com/publication/capped-nascent-rna-sequencing-reveals-novel-therapy-responsive-enhancers-in-prostate-cancer/"/>
    <id>https://www.yaobio.com/publication/capped-nascent-rna-sequencing-reveals-novel-therapy-responsive-enhancers-in-prostate-cancer/</id>
    <published>2022-04-08T18:41:29.000Z</published>
    <updated>2025-04-23T04:03:22.947Z</updated>
    
    
    
    
    <category term="publication" scheme="https://www.yaobio.com/publication/"/>
    
    
  </entry>
  
  <entry>
    <title>A comparison of experimental assays and analytical methods for genome-wide identification of active enhancers</title>
    <link href="https://www.yaobio.com/publication/a-comparison-of-experimental-assays-and-analytical-methods-for-genome-wide-identification-of-active-enhancers/"/>
    <id>https://www.yaobio.com/publication/a-comparison-of-experimental-assays-and-analytical-methods-for-genome-wide-identification-of-active-enhancers/</id>
    <published>2022-01-06T14:42:06.000Z</published>
    <updated>2025-04-23T04:03:22.947Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Mounting evidence supports the idea that transcriptional patterns serve as more specific identifiersof active enhancers than histone marks; however, the optimal strategy to identify active enhancers both experimentally and computationally has not been determined. Here, we compared 13 genome-wide RNA sequencing (RNA-seq) assays in K562 cells and show that nuclear run-on followed by cap-selection assay (GRO&#x2F;PRO-cap) has advantages in enhancer RNA detection and active enhancer identification. We also introduce a tool, peak identifier for nascent transcript starts (PINTS), to identify active promoters and enhancers genome wide and pinpoint the precise location of 5′ transcription start sites. Finally, we compiled a comprehensive enhancer candidate compendium based on the detected enhancer RNA (eRNA) transcription start sites (TSSs) available in 120 cell and tissue types, which can be accessed at <a href="https://pints.yulab.org/">https://pints.yulab.org</a>. With knowledge of the best available assays and pipelines, this large-scale annotation of candidate enhancers will pave the way for selection and characterization of their functions in a timeand labor-efficient manner.</p><h2 id="Accepted-manuscript"><a href="#Accepted-manuscript" class="headerlink" title="Accepted manuscript"></a>Accepted manuscript</h2><embed src="/assets/archives/2022_eRNA_comparison_PINTS.pdf" width="100%" height="1000" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;Mounting evidence supports the idea that transcriptional patterns serve as more specific identifiers
of active enhancers than histone marks; however, the optimal strategy to identify active enhancers 
both experimentally and computationally has not been determined. Here, we compared 13 genome-wide RNA 
sequencing (RNA-seq) assays in K562 cells and show that nuclear run-on followed by cap-selection assay 
(GRO&amp;#x2F;PRO-cap) has advantages in enhancer RNA detection and active enhancer identification. We also 
introduce a tool, peak identifier for nascent transcript starts (PINTS), to identify active promoters 
and enhancers genome wide and pinpoint the precise location of 5′ transcription start sites. Finally, 
we compiled a comprehensive enhancer candidate compendium based on the detected enhancer RNA (eRNA) 
transcription start sites (TSSs) available in 120 cell and tissue types, which can be accessed at 
&lt;a href=&quot;https://pints.yulab.org/&quot;&gt;https://pints.yulab.org&lt;/a&gt;. With knowledge of the best available assays and 
pipelines, this large-scale annotation of candidate enhancers will pave the way for selection and 
characterization of their functions in a timeand labor-efficient manner.&lt;/p&gt;</summary>
    
    
    
    <category term="publication" scheme="https://www.yaobio.com/publication/"/>
    
    
  </entry>
  
  <entry>
    <title>Case Study: Resolving the Mystery of a Full Linux Root Disk</title>
    <link href="https://www.yaobio.com/posts/case-study-resolving-the-mystery-of-a-full-linux-root-disk/"/>
    <id>https://www.yaobio.com/posts/case-study-resolving-the-mystery-of-a-full-linux-root-disk/</id>
    <published>2021-09-04T00:47:40.000Z</published>
    <updated>2025-04-23T04:03:22.946Z</updated>
    
    <content type="html"><![CDATA[<p>In the world of genomics research, every data point carries the potential to unlock the secrets of life itself. However, as genomics datasets grow in size and complexity, so do the challenges of managing the associated disk space. This is a story of a recent journey that began with a simple task: using the Integrative Genomics Viewer (IGV) to inspect many signal tracks. Little did I know that this journey would lead to a deep dive into the enigmatic realm of Linux file handles and the secrets they held.</p><h2 id="The-Enigmatic-Message"><a href="#The-Enigmatic-Message" class="headerlink" title="The Enigmatic Message"></a>The Enigmatic Message</h2><p>The story unfolds in the midst of my genomics analysis. I was inspecting numerous signal tracks with IGV. My workflow consisted of working in batched samples—inspect, analyze, delete. As I diligently removed the tracks from IGV and deleted the corresponding files from the filesystem, all seemed well. That was until an unexpected message disrupted my rhythm: “Root disk full.”</p><img src="/posts/case-study-resolving-the-mystery-of-a-full-linux-root-disk/disk-space-low.png" class="" title="Low disk space on root"><h2 id="The-Perplexing-Discrepancy"><a href="#The-Perplexing-Discrepancy" class="headerlink" title="The Perplexing Discrepancy"></a>The Perplexing Discrepancy</h2><p>The message left me bewildered. How could the root disk be full when I had meticulously deleted the files associated with the inspected signal tracks? I first checked the situation with the <code>df</code> command and confirmed that the system still believed it was running out of space.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df -h </span><br></pre></td></tr></table></figure><blockquote>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Filesystem        Size  Used Avail Use% Mounted on</span><br><span class="line">tmpfs             50G  3.0M   50G   1% /run</span><br><span class="line">/dev/sda1         58G   58G  455M 100% /</span><br><span class="line">...</span><br></pre></td></tr></table></figure></blockquote><p>Determined to solve this mystery, I turned to the <code>du</code> command, the venerable tool for disk usage analysis. Yet, to my astonishment, <code>du</code> reported a different story. It indicated that the disk had ample space, with only 24G being used.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo du -h --max-depth=1 /</span><br></pre></td></tr></table></figure><blockquote>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">8.3G/usr</span><br><span class="line">5.4G/home</span><br><span class="line">7.1M/tmp</span><br><span class="line">4.9G/snap</span><br><span class="line">5.1G/var</span><br><span class="line">...</span><br><span class="line">24G.</span><br></pre></td></tr></table></figure></blockquote><h2 id="The-Unyielding-File-Handles"><a href="#The-Unyielding-File-Handles" class="headerlink" title="The Unyielding File Handles"></a>The Unyielding File Handles</h2><p>The perplexing discrepancy between the reported disk usage and the <code>du</code> output left me scratching my head. What could possibly be holding onto that disk space? I couldn’t help but wonder if I had missed something when running the <code>du</code> command. But no, I had executed the command on the entire root directory with all the privileges of an admin. So, what other mysterious forces could be at play?</p><p>A crucial revelation came to light as I delved deeper into the mystery. There may be files that were still open despite being deleted. The question now was: how do I unearth these orphaned files and identify the processes holding them hostage?</p><p>To answer this question, I turned to the ‘lsof’ command. Specifically, I used the following command to search for orphaned files and the processes that kept them open:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lsof +aL1 /</span><br></pre></td></tr></table></figure><p>The output was illuminating. A single Java process, with ID <code>455114</code>,  was responsible for holding onto all the orphaned files, each contributing to the discrepancy in disk space usage. This was evident from the <code>SIZE/OFF</code> column, which displayed substantial figures.</p><blockquote>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">COMMAND       PID    USER   FD   TYPE DEVICE   SIZE/OFF NLINK    NODE NAME</span><br><span class="line">java       455114      li  118r   REG    8,1  624602003     0 1552486 /home/li/.local/share/Trash/expunged/751520316 (deleted)</span><br><span class="line">java       455114      li  119r   REG    8,1 1180123471     0 1552300 /home/li/.local/share/Trash/expunged/2560126835 (deleted)</span><br><span class="line">java       455114      li  129r   REG    8,1  225277230     0 1578319 /home/li/.local/share/Trash/expunged/2423833192 (deleted)</span><br><span class="line">...</span><br><span class="line">java       455114      li  221r   REG    8,1 2846628790     0 1582420 /home/li/.local/share/Trash/expunged/2658608637 (deleted)</span><br></pre></td></tr></table></figure></blockquote><h2 id="The-Pursuit-of-Resolution"><a href="#The-Pursuit-of-Resolution" class="headerlink" title="The Pursuit of Resolution"></a>The Pursuit of Resolution</h2><p>Armed with this newfound knowledge, I was determined to catch the ghost occupying my disk space. The first step in this quest was to identify the program behind those tenacious file handles. I began my search by unmasking the process responsible for these file handles. To do this, I used the <code>ps aux</code> command with <code>grep</code> to filter the results based on the process ID (455114) I discovered earlier. The command looked like this:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux | grep 455114</span><br></pre></td></tr></table></figure><p>The result was a revealing snapshot of the process:</p><blockquote>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">li   455114  0.3  0.4 22382052 2385040 pts/6 Sl+ Aug30  20:32 java -showversion --module-path=/home/li/IGV_Linux_2.16.2/lib -Xmx8g @/home/li/IGV_Linux_2.16.2/igv.args -Dapple.laf.useScreenMenuBar=true -Djava.net.preferIPv4Stack=true -Djava.net.useSystemProxies=true @/home/li/.igv/java_arguments --module=org.igv/org.broad.igv.ui.Main</span><br></pre></td></tr></table></figure></blockquote><p>Ah, the culprit was none other than IGV itself! Despite removing the tracks from IGV and deleting the corresponding files from the filesystem, IGV had clung onto the file handles, refusing to release them. The pieces of the puzzle were finally coming together, and a solution was now within reach.</p><p>Right after I terminated the IGV instance, a lot of disk space got released, and the problem was solved!</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df -h</span><br></pre></td></tr></table></figure><blockquote>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Filesystem        Size  Used Avail Use% Mounted on</span><br><span class="line">tmpfs             50G  3.0M   50G   1% /run</span><br><span class="line">/dev/sda1         58G   18G   41G  31% /</span><br><span class="line">...</span><br></pre></td></tr></table></figure></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;In the world of genomics research, every data point carries the potential to unlock the secrets of 
life itself. However, as genomics dat</summary>
      
    
    
    
    <category term="posts" scheme="https://www.yaobio.com/posts/"/>
    
    
    <category term="technical_docs" scheme="https://www.yaobio.com/tags/technical-docs/"/>
    
    <category term="debug" scheme="https://www.yaobio.com/tags/debug/"/>
    
  </entry>
  
  <entry>
    <title>PINTS and PINTS web portal</title>
    <link href="https://www.yaobio.com/tools/pints-and-pints-web-portal/"/>
    <id>https://www.yaobio.com/tools/pints-and-pints-web-portal/</id>
    <published>2021-03-07T23:44:11.000Z</published>
    <updated>2025-04-23T04:03:22.948Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>If you are interested in the detailed methodology, please refer to our manuscript, <em><a href="/publication/a-comparison-of-experimental-assays-and-analytical-methods-for-genome-wide-identification-of-active-enhancers/" title="A comparison of experimental assays and analytical methods for genome-wide identification of active enhancers">A comparison of experimental assays and analytical methods for genome-wide identification of active enhancers</a></em>, for more information.</p></blockquote><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p><strong>P</strong>eak <strong>I</strong>dentifier for <strong>N</strong>ascent <strong>T</strong>ranscript <strong>S</strong>tarts (PINTS) is a software that helps locate potential regulatory elements (promoters and enhancers) genome-wide from nascent transcript sequencingdata, like GRO&#x2F;PRO-cap libraries, which are specifically enriched for signals from <strong>t</strong>ranscription <strong>s</strong>tart <strong>s</strong>ites (TSSs).</p><p><object data="pints_intro.svg" width="50%" class="svg-animation"></object></p><p>PINTS web portal is a comprehensive catalog of promoters and enhancers, and all have support from transcriptional evidence. Besides the catalog database, the portal also allows users to upload their genomic loci of interest and analyze the loci with state-of-the-art annotations. The portal is a containerized web service powered by Django, celery, and other open-source packages.</p><h2 id="Availability"><a href="#Availability" class="headerlink" title="Availability"></a>Availability</h2><p>PINTS executable files are packed and distributed on both <a href="https://pypi.org/project/pyPINTS/">PyPI</a> and <a href="https://bioconda.github.io/recipes/pypints/README.html#package-pypints">bioconda</a>. You can install PINTS like any other standard Python package with <a href="https://pip.pypa.io/en/stable/">pip</a> (<code>pip install pyPINTS</code>) or <a href="https://docs.conda.io/en/latest/">conda</a> (<code>conda install -c bioconda pypints</code>). The source code is available on <a href="https://github.com/hyulab/pints">GitHub</a>.</p><p>PINTS web portal is freely accessible at <a href="https://pints.yulab.org/">pints.yulab.org</a>.</p><h2 id="Changelog"><a href="#Changelog" class="headerlink" title="Changelog"></a>Changelog</h2><h3 id="PINTS"><a href="#PINTS" class="headerlink" title="PINTS"></a>PINTS</h3><h4 id="1-1-15"><a href="#1-1-15" class="headerlink" title="1.1.15"></a>1.1.15</h4><p>Release date: 2024-12-22</p><ul><li><strong>[Fixed]</strong>: PINTS (boundary extender) may quit when warnings are threw in third-party libraries.</li></ul><h4 id="1-1-14"><a href="#1-1-14" class="headerlink" title="1.1.14"></a>1.1.14</h4><p>Release date: 2024-10-10</p><ul><li><strong>[Fixed]</strong>: some csi index files not deleted after the entire peak calling process (related to ver<a href="#1-1-12">1.1.12</a>).</li></ul><h4 id="1-1-13"><a href="#1-1-13" class="headerlink" title="1.1.13"></a>1.1.13</h4><p>Release date: 2024-09-09</p><ul><li><strong>[Fixed]</strong>: PINTS may quit in cases where the sets of chromosomes in the forward and reverse bigwigs are not 100% identical</li></ul><h4 id="1-1-12"><a href="#1-1-12" class="headerlink" title="1.1.12"></a>1.1.12</h4><p>Release date: 2024-07-21</p><ul><li><strong>[Changed]</strong>: improved IO performance by up to ~40% when working with bigWig inputs</li><li><strong>[Changed]</strong>: years in comments</li><li><strong>[Added]</strong>: pints_counter for generating count matrix</li><li><strong>[Fixing]</strong>: switched to csi index for better handling of large chromosomes. But more tests regarding memory pressure are needed</li><li><strong>[Fixed]</strong>: csi index files not deleted after the entire peak calling process</li></ul><h4 id="1-1-11"><a href="#1-1-11" class="headerlink" title="1.1.11"></a>1.1.11</h4><p>Skipped</p><h4 id="1-1-10"><a href="#1-1-10" class="headerlink" title="1.1.10"></a>1.1.10</h4><p>Release date: 2023-11-07</p><ul><li><strong>[Changed]</strong>: Removed warning filters in extension_engine as warnings from other packages maybreak downstream analysis.</li><li><strong>[Changed]</strong>: years in comments</li></ul><h4 id="1-1-9"><a href="#1-1-9" class="headerlink" title="1.1.9"></a>1.1.9</h4><p>Release date: 2023-05-11</p><ul><li><strong>[Added]</strong>: A new QC script for evaluating TSS enrichment (over gene body regions)</li><li><strong>[Changed]</strong>: Report scale factors when using <code>pints_visualizer</code></li><li><strong>[Changed]</strong>: Switched <code>formatter_class</code> for all executable scripts’ argument parsers from <code>HelpFormatter</code> to <code>ArgumentDefaultsHelpFormatter</code>, so that default values will be printed when running commands like <code>pints_caller --help</code></li><li><strong>[Fixed]</strong>: Added boundary caps to avoid <code>ValueError</code> when calling <code>pysam.TabixFile.fetch</code>(Corresponding to GitHub issue #6)</li></ul><h4 id="1-1-8"><a href="#1-1-8" class="headerlink" title="1.1.8"></a>1.1.8</h4><p>Release date: 2022-10-08</p><ul><li><strong>[Fixed]</strong>: When no divergent&#x2F;bidirectional peaks are detected, PINTS may throw exceptions. In this version, empty predictions will be skipped, so errors like <code>ERROR: Requested column 12, but database file stdin only has fields 1 - 0.</code> will be avoided (related GitHub issue <a href="https://github.com/hyulab/PINTS/issues/12">#12</a>).</li><li><strong>[Changed]</strong>: Since PINTS will automatically adjust the value of <code>--min-mu-percent</code>, now it prints info instead of a warning message when <code>--min-mu-percent</code> related issues are detected.</li><li><strong>[Changed]</strong>: Reduce redundancy in the function <code>peak_calling</code> by abstracting statements about parsing input files.</li><li><strong>[Added]</strong>: Added a new QC metric on the number of significant calls. If the number of significant calls is toolarge, PINTS will throw a warning message and suggest users switch to a more strict FDR cutoff.</li></ul><h4 id="1-1-7"><a href="#1-1-7" class="headerlink" title="1.1.7"></a>1.1.7</h4><p>Release date: 2022-09-16</p><ul><li><strong>[Added]</strong>: unit test cases</li><li><strong>[Added]</strong>: Github issue templates</li><li><strong>[Changed]</strong>: Improved the logic of on-the-fly QC. If QC is enabled, now PINTS tries to directly adjust corresponding parameter (for now only <code>--min-mu-percent</code>) and log the changes. This behavior can be repressed by using <code>--disable-qc</code>.</li></ul><h4 id="1-1-6"><a href="#1-1-6" class="headerlink" title="1.1.6"></a>1.1.6</h4><p>Release date: 2022-07-05</p><ul><li><strong>[Added]</strong>: Added chromosome length check when using BAM files as inputs</li><li><strong>[Changed]</strong>: Simplified on-the-fly QC messages. So warning messages of the same type only show up once at the end of the log file.</li><li><strong>[Changed]</strong>: Dropped peak length limits for empirical LER.</li><li><strong>[Fixed]</strong>: Fixed inappropriate usage of <code>str.find</code> in <code>annotate_tre_with_epig_info</code>.</li></ul><h4 id="1-1-5"><a href="#1-1-5" class="headerlink" title="1.1.5"></a>1.1.5</h4><p>Release date: 2022-06-16</p><ul><li><strong>[Fixed]</strong>: Add explicit type conversion to avoid <code>AttributeError: Can only use str accessor with string values</code></li></ul><h4 id="1-1-4"><a href="#1-1-4" class="headerlink" title="1.1.4"></a>1.1.4</h4><p>Release date: 2022-06-13</p><ul><li><strong>[Fixed]</strong>: fixed typos in readme; </li><li><strong>[Removed]</strong>: Removed scaffold codes; </li><li><strong>[Changed]</strong>: changed default output from pints_boundary_extender to standard bed format</li><li><strong>[Changed]</strong>: moved codes from scripts to PINTS lib for more accurate test coverage analysis;</li></ul><h4 id="1-1-0-1-1-3"><a href="#1-1-0-1-1-3" class="headerlink" title="1.1.0 (1.1.3)"></a>1.1.0 (1.1.3)</h4><p>Release date: 2022-03-16 (for 1.1.0) and 2022-03-21 (for 1.1.3)</p><ul><li><strong>[Added]</strong>: Source distribution to CI&#x2F;CD for creating conda packages</li><li><strong>[Added]</strong>: Added <code>MANIFEST.in</code> file to include <code>versioneer.py</code> in the source distribution</li><li><strong>[Added]</strong>: empirical LER</li><li><strong>[Added]</strong>: On the fly QC</li><li><strong>[Changed]</strong>: Switched versioning schema from PEP 440 to <code>major_ver</code>.<code>middle_ver</code>.<code>minor_ver</code>. The first two vers will be defined by tags; the <code>minor_ver</code> will be inferred automatically from commit distance.</li><li><strong>[Changed]</strong>: Changed the default value for <code>--alpha</code> (for combining nearby peaks) to 0.3.</li><li><strong>[Changed]</strong>: Renamed <code>README.md</code>.</li><li><strong>[Changed]</strong>: Improved the implementation of independent filtering</li><li><strong>[Changed]</strong>: Improved code readability with Pylint</li><li><strong>[Removed]</strong>: Scaffolding parameters and simplified naming schema.</li></ul><h4 id="0-0-1-post0-dev8"><a href="#0-0-1-post0-dev8" class="headerlink" title="0.0.1.post0.dev8"></a>0.0.1.post0.dev8</h4><p>Release date: 2022-01-07</p><ul><li><strong>[Changed]</strong>: Add requests to <code>install_requires</code>.</li></ul><h4 id="0-0-1-post0-dev7"><a href="#0-0-1-post0-dev7" class="headerlink" title="0.0.1.post0.dev7"></a>0.0.1.post0.dev7</h4><p>Release date: 2022-01-07</p><ul><li><strong>[Changed]</strong>: Updated readme and help message</li></ul><h4 id="0-0-1-post0-dev6"><a href="#0-0-1-post0-dev6" class="headerlink" title="0.0.1.post0.dev6"></a>0.0.1.post0.dev6</h4><p>Release date: 2022-01-05</p><ul><li><strong>[Fixed]</strong>: Fixed timestamp issue when creating log file</li></ul><h4 id="0-0-1-post0-dev5"><a href="#0-0-1-post0-dev5" class="headerlink" title="0.0.1.post0.dev5"></a>0.0.1.post0.dev5</h4><p>Release date: 2022-01-04</p><ul><li><strong>[Added]</strong>: Introduced version check, which prints update hints if current version of PINTS is out-dated.</li></ul><h4 id="0-0-1-post0-dev3"><a href="#0-0-1-post0-dev3" class="headerlink" title="0.0.1.post0.dev3"></a>0.0.1.post0.dev3</h4><p>Release date: 2021-10-30</p><ul><li><strong>[Changed]</strong>: Added pyBigWig, biopython, and matplotlib into <code>setup.install_requires</code>.</li><li><strong>[Added]</strong>: Introduced a new module for refining peak calls with epigenomic evidence from PINTS webserver. This feature can be activated by using <code>--epig-annotation &lt;biosample_name&gt;</code>.</li><li><strong>[Added]</strong>: error check for lowly sequenced libraries.</li></ul><h4 id="0-0-1-post0-dev2"><a href="#0-0-1-post0-dev2" class="headerlink" title="0.0.1.post0.dev2"></a>0.0.1.post0.dev2</h4><p>Release date: 2021-08-04</p><ul><li><strong>[Added]</strong>: Configured CI&#x2F;CD for uploading PINTS to PyPI.</li><li><strong>[Added]</strong>: Added CI&#x2F;CD badge in README.</li></ul><h4 id="0-0-1-post0-dev1"><a href="#0-0-1-post0-dev1" class="headerlink" title="0.0.1.post0.dev1"></a>0.0.1.post0.dev1</h4><p>Release date: 2021-06-03</p><p>Initial implementation.</p><h3 id="PINTS-web-portal"><a href="#PINTS-web-portal" class="headerlink" title="PINTS web portal"></a>PINTS web portal</h3><h4 id="2023v1"><a href="#2023v1" class="headerlink" title="2023v1"></a>2023v1</h4><ul><li><strong>[Added]</strong>: Included PRO-cap libraries for HCT116</li><li><strong>[Changed]</strong>: Updated epigenomic annotation to cCRE v4</li><li><strong>[Changed]</strong>: Updated functional characterization info from NCBI RefSeq</li><li><strong>[Changed]</strong>: Updated TF binding site annotation to JASPAR 2024</li></ul><h4 id="2022v1"><a href="#2022v1" class="headerlink" title="2022v1"></a>2022v1</h4><p>Release date: 2022-07-17</p><ul><li><strong>[Added]</strong>: Increased biosample coverage by adding PRO-cap libraries for:<ul><li>GM18507, GM19238 from Kristjánsdóttir <em>et al.</em> 2020 (DOI: 10.1038&#x2F;s41467-020-19829-z)</li><li>MCF7 from Hou <em>et al.</em> 2022 (DOI: 10.1016&#x2F;j.celrep.2022.110944)</li><li>A673, Caco-2, and MCF 10A from the ENCODE portal (using DOI: 10.1038&#x2F;s41587-022-01211-7 as a placeholder for now, will update the study link after the manuscript is published)</li></ul></li><li><strong>[Changed]</strong>: Updated epigenomic annotation to cCRE v3</li><li><strong>[Changed]</strong>: Updated TF binding site annotation to JASPAR 2022</li><li><strong>[Changed]</strong>: Updated functional characterization info for HepG2 by including consistent enhancer calls from Klein <em>et al.</em> 2020.</li><li><strong>[Changed]</strong>: Switched to PINTS <a href="#1-1-6">1.1.6</a>.</li><li><strong>[Deprecated]</strong>: Removed bidirectional elements identified from RAMPAGE&#x2F;CAGE libraries that overlap with protein-coding exons (except $5^\prime$ UTR).</li></ul><h4 id="2021v1"><a href="#2021v1" class="headerlink" title="2021v1"></a>2021v1</h4><p>Release date: 2021-10-23</p><p>Initial release.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;P&lt;/strong&gt;eak &lt;strong&gt;I&lt;/strong&gt;dentifier for &lt;strong&gt;N&lt;/strong&gt;ascent &lt;strong&gt;T&lt;/strong&gt;ranscript &lt;strong&gt;S&lt;/strong&gt;tarts (PINTS) is a software that helps 
locate potential regulatory elements (promoters and enhancers) genome-wide from nascent transcript sequencing
data, like GRO&amp;#x2F;PRO-cap libraries, which are specifically enriched for signals from &lt;strong&gt;t&lt;/strong&gt;ranscription &lt;strong&gt;s&lt;/strong&gt;tart &lt;strong&gt;s&lt;/strong&gt;ites (TSSs).&lt;/p&gt;
&lt;p&gt;&lt;object data=&quot;pints_intro.svg&quot; width=&quot;50%&quot; class=&quot;svg-animation&quot;&gt;&lt;/object&gt;&lt;/p&gt;
&lt;p&gt;PINTS web portal is a comprehensive catalog of promoters and enhancers, and all have support from 
transcriptional evidence. Besides the catalog database, the portal also allows users to upload 
their genomic loci of interest and analyze the loci with state-of-the-art annotations. 
The portal is a containerized web service powered by Django, celery, and other open-source packages.&lt;/p&gt;</summary>
    
    
    
    <category term="tools" scheme="https://www.yaobio.com/tools/"/>
    
    
  </entry>
  
  <entry>
    <title>BTRY 4381/6381 Biomedical Data Mining and Modeling</title>
    <link href="https://www.yaobio.com/teaching/btry-4381-6381-biomedical-data-mining-and-modeling/"/>
    <id>https://www.yaobio.com/teaching/btry-4381-6381-biomedical-data-mining-and-modeling/</id>
    <published>2020-09-01T00:00:00.000Z</published>
    <updated>2025-04-23T04:03:22.948Z</updated>
    
    <content type="html"><![CDATA[<p>A biomedical data science course using Python and available bioinformatics tools and techniques for the analysis of molecular biological data, including biosequences, microarrays, and networks. This course emphasizes practical skills rather than theory. Topics include advanced Python programming, R and Bioconductor, sequence alignment, MySQL database (DBI), web programming and services (CGI and django), genomics and proteomics data mining and analysis, machine learning, and methods for inferring and analyzing regulatory, protein-protein interaction, and metabolite networks.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;A biomedical data science course using Python and available bioinformatics tools and techniques for the analysis of 
molecular biological</summary>
      
    
    
    
    <category term="teaching" scheme="https://www.yaobio.com/teaching/"/>
    
    
  </entry>
  
  <entry>
    <title>Mastering IGV: Tips and Tricks for Visualizing Sequencing Data</title>
    <link href="https://www.yaobio.com/posts/mastering-igv-tips-and-tricks-for-visualizing-sequencing-data/"/>
    <id>https://www.yaobio.com/posts/mastering-igv-tips-and-tricks-for-visualizing-sequencing-data/</id>
    <published>2020-08-01T19:08:23.000Z</published>
    <updated>2025-04-23T04:03:22.944Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>If a human being had actually looked at his blood, anywhere along the way, instead of just running tests through the computer… parasites would have jumped right out at them.</p><p>“Failure to Communicate.” <em>House M.D.</em></p></blockquote><p>There is a case in the TV show House M.D., where a parasite infected the patient; Dr. House’s team runs many tests and gets no clue. In the end, Dr. House tells the team to look at the blood sample through a microscope instead of using numbers from instruments. The team does so and instantly sees the parasite. Even though the settings of the disease may not be very accurate, it leaves me with a profound impression. The same situation can also happen in bioinformatics, as we do many tests to identify targets of interest or evaluate our confidence in conclusions. However, we should be aware that these <em>tests are all based on some assumptions, and it’s always beneficial to visually check the data to have an intuitive impression that the data fit the assumptions</em>. Integrated Genome Browser (<code>IGV</code>) is a powerful tool for visualizing sequencing data. In this post, I’ll share some of my tricks for making IGV even more useful.</p><h2 id="Case-1-There-are-a-bunch-of-loci-that-need-to-be-checked-visually"><a href="#Case-1-There-are-a-bunch-of-loci-that-need-to-be-checked-visually" class="headerlink" title="Case 1: There are a bunch of loci that need to be checked visually"></a>Case 1: There are a bunch of loci that need to be checked visually</h2><p>If you need to visually check many regions of interest in IGV, you can use a batch script to automate the process. The IGV <a href="https://github.com/igvteam/igv/wiki/Batch-commands">batch script</a> language allows you to generate a script file that tells IGV which regions to display and where to save the output. Instead of learning the details about this minimal language yourself, you can directly use <code>bedtools</code> to create a batch script for a list of loci in a bed file. In the following example, genomic loci in <code>loci.bed</code> will first be extended 200 bp both upstream and downstream,then a batch script covering these regions will be saved to the file <code>batch.script</code>.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">snapshots will be saved to `path_to_store_snapshots`</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">-slop indicates the number of flanking base pairs on</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">both the left and right of the interested regions to be</span> </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">extended <span class="keyword">in</span> the captured images (0 <span class="keyword">for</span> keep them as they are)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">I recommend <span class="built_in">set</span> the output img format to be svg or eps</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">the resolution <span class="keyword">for</span> png file is so low</span></span><br><span class="line">bedtools igv -path path_to_store_snapshots \</span><br><span class="line">-i loci.bed -slop 200 \</span><br><span class="line">-img svg &gt; batch.script</span><br></pre></td></tr></table></figure><p>After loading the tracks you want to see in IGV, click <code>Tools</code>&gt;<code>Run Batch Script...</code> and load the <code>batch.script</code> file, IGV will get start capturing snapshots of each locus. If the process is slow, you can split the bed file and generate batch scripts for each subset, then load them into separate instances of IGV.</p><img src="/posts/mastering-igv-tips-and-tricks-for-visualizing-sequencing-data/igv_load_batch_script.png" class="" title="Load batch script"><h2 id="Case-2-Frequently-used-annotations-are-not-listed-in-the-default-server"><a href="#Case-2-Frequently-used-annotations-are-not-listed-in-the-default-server" class="headerlink" title="Case 2: Frequently used annotations are not listed in the default server"></a>Case 2: Frequently used annotations are not listed in the default server</h2><p>The IGV team maintains a fabulous web server with some commonly used annotations (like gene annotations from the GENCODE project) or datasets (like ChIP-seq alignments from the ENCODE project); by simply selecting the annotations of interest from <code>File</code>&gt;<code>Load from Server...</code>, you can load them to your current session. One small pitfall with this function is that the annotations or datasets are not always up-to-date; for some frequently used files (or customized files), you may want them listed there. In this case, you should consider setting up your data server for IGV. </p><h3 id="Step-1-Copy-precompiled-data-files-from-IGV"><a href="#Step-1-Copy-precompiled-data-files-from-IGV" class="headerlink" title="Step 1: Copy precompiled data files from IGV"></a>Step 1: Copy precompiled data files from IGV</h3><p>You can get a copy of all genome files that IGV is currently using from their GitHub repo:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/igvteam/igv.git</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">igv team removed genome files <span class="keyword">in</span> commit 218f873</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">so we need to check out from one commit before the deletion,</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">which</span> refers to commit beb4f48</span></span><br><span class="line">git checkout beb4f48e04</span><br></pre></td></tr></table></figure><p>After checkout, you can copy the entire <code>igv/genomes</code> folder to a new place (assuming it’s <code>/nas1/references</code>) and set up your data server.</p><h3 id="Step-2-Install-and-configure-a-web-server"><a href="#Step-2-Install-and-configure-a-web-server" class="headerlink" title="Step 2: Install and configure a web server"></a>Step 2: Install and configure a web server</h3><p>If you’ve already had a web server, then you can move to step 3. For Mac users, you can install Nginx with <a href="https://brew.sh/">Homebrew</a>:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install nginx</span><br></pre></td></tr></table></figure><p>By default, the configuration file for Nginx (installed by Homebrew) is located at <code>/usr/local/etc/nginx/nginx.conf</code>. In the <code>http</code> section, add a new server configuration as follows:</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">  <span class="attribute">listen</span> <span class="number">80</span>;</span><br><span class="line">  <span class="attribute">listen</span> [::]:<span class="number">80</span>;</span><br><span class="line">  <span class="comment"># if you have a domain, replace `ref.yaobio.com` with your own domain</span></span><br><span class="line">  <span class="comment"># if you don&#x27;t have one, and only want to access the web server locally</span></span><br><span class="line">  <span class="comment"># you can replace it with localhost</span></span><br><span class="line">  <span class="attribute">server_name</span> ref.yaobio.com;</span><br><span class="line">  </span><br><span class="line">  <span class="section">location</span> / &#123;</span><br><span class="line">    <span class="comment"># replace this path with where you put the data files from IGV</span></span><br><span class="line">    <span class="attribute">root</span>   /nas1/references;</span><br><span class="line">    <span class="attribute">index</span>  index.html index.htm;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Reload the configurations to make changes effective:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx reload</span><br></pre></td></tr></table></figure><p>Create a new directory (<code>annotations</code>) in <code>/nas1/references</code>.Now the structure of this folder is something like</p><ul><li>references<ul><li>db<ul><li>1kg_ref</li><li>…</li><li>hg19</li><li>hg38</li><li>mm10</li><li>…</li></ul></li><li>sizes<ul><li>1kg_ref.chrom.sizes</li><li>…</li><li>hg19.chrom.sizes</li><li>hg38.chrom.sizes</li><li>mm10.chrom.sizes</li><li>…</li></ul></li><li>annotations</li><li>genomes.tab</li><li>genomes.txt</li></ul></li></ul><h3 id="Step-3-Save-new-annotations-and-modify-data-files"><a href="#Step-3-Save-new-annotations-and-modify-data-files" class="headerlink" title="Step 3: Save new annotations and modify data files"></a>Step 3: Save new annotations and modify data files</h3><p>Let’s assume you have a new annotation file processed (e.g., processed GENCODE v35 for hg38 with the pipeline we mentioned in the previous <a href="/posts/collection-of-commonly-used-references-in-bioinformatic-analysis/" title="post">post</a>); now, you can move the file to <code>/nas1/references/annotations</code>. Then you need to modify the default genome and data registry:</p><ol><li><p>Change the content of <code>db/hg38/hg38_dataServerRegistry.txt</code> from <code>https://s3.amazonaws.com/igv.org.genomes/hg38/hg38_annotations.xml</code> to <code>https://ref.yaobio.com/db/hg38/hg38_annotations.xml</code></p></li><li><p>Add the following item to <code>db/hg38/hg38_annotations.xml</code>:</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">Resource</span> <span class="attr">name</span>=<span class="string">&quot;Gencode V35&quot;</span> <span class="attr">path</span>=<span class="string">&quot;http://ref.yaobio.com/annotations/gencode.v35.annotation.sorted.gtf.gz&quot;</span> <span class="attr">index</span>=<span class="string">&quot;http://ref.yaobio.com/annotations/gencode.v35.annotation.sorted.gtf.gz.tbi&quot;</span> <span class="attr">hyperlink</span>=<span class="string">&quot;http://www.gencodegenes.org/&quot;</span>/&gt;</span></span><br></pre></td></tr></table></figure></li></ol><h3 id="Step-4-Change-the-data-server-setting-in-IGV"><a href="#Step-4-Change-the-data-server-setting-in-IGV" class="headerlink" title="Step 4: Change the data server setting in IGV"></a>Step 4: Change the data server setting in IGV</h3><p>Now in IGV, click <code>View</code>&gt;<code>Preferences</code>&gt;<code>Advanced</code>, and replace the previous value in <code>Data registry url</code> with <code>http://ref.yaobio.com/db/$$/$$_dataServerRegistry.txt</code>. Finally, save the changes, and restart IGV; you should be able to see and load newly added annotations into IGV.</p><h2 id="General-tips"><a href="#General-tips" class="headerlink" title="General tips"></a>General tips</h2><h3 id="Always-load-bed-files-with-indices"><a href="#Always-load-bed-files-with-indices" class="headerlink" title="Always load bed files with indices"></a>Always load bed files with indices</h3><p>Always create indices for bed files before loading them into IGV. Otherwise, IGV will read every interval into memory and generate indexes on the fly, consuming excessive memory and time. You can use <code>tabix</code> to generate an index for interval files before loading them into IGV. This practice can greatly reduce memory usage and computation time. Let’s say we have an interval bed file <code>test_file_1.bed.gz</code>, it has 18M records; after loading this file into IGV without index, IGV takes more than <strong>25GB</strong> of memory! </p><img src="/posts/mastering-igv-tips-and-tricks-for-visualizing-sequencing-data/igv_without_index.png" class="" title="Without index, IGV takes significant amount of memory"><p>But if you use <code>tabix test_file_1.bed.gz</code> to generate the index first, and then feed IGV with the same file, it only takes <strong>2GB</strong>!</p><img src="/posts/mastering-igv-tips-and-tricks-for-visualizing-sequencing-data/igv_with_index.png" class="" title="With index, IGV takes relatively less memory"><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>IGV is a valuable tool for visualizing sequencing data, and these tips and tricks can help you make the most of its capabilities. By using batch scripting, setting up a personal data server, and optimizing bed file loading with indices, you can streamline your bioinformatics workflows and gain more insights from your data.</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;If a human being had actually looked at his blood, anywhere along the way, 
instead of just running tests through the comput</summary>
      
    
    
    
    <category term="posts" scheme="https://www.yaobio.com/posts/"/>
    
    
    <category term="technical_docs" scheme="https://www.yaobio.com/tags/technical-docs/"/>
    
  </entry>
  
  <entry>
    <title>Setting up a handy research environment on Linux servers</title>
    <link href="https://www.yaobio.com/posts/setting-up-a-handy-research-environment-on-linux-servers/"/>
    <id>https://www.yaobio.com/posts/setting-up-a-handy-research-environment-on-linux-servers/</id>
    <published>2020-07-20T09:31:47.000Z</published>
    <updated>2025-04-23T04:03:22.942Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Login-with-SSH-key"><a href="#Login-with-SSH-key" class="headerlink" title="Login with SSH key"></a>Login with SSH key</h2><p>Putting your password every time you log into a server via SSH can be tiresome, especially if your password is long.One way to make life easier and safer is by using SSH keys.</p><ol><li>In the terminal of your local machine, type in <code>ssh-keygen</code>. By default, the keys will be exported to <code>~/.ssh/id_rsa</code>; using the default is okay in most cases, but if you have multiple keys and want to avoid conflicts, you can change the destination. </li><li>When it prompts you to enter a passphrase, you can click Enter (empty passphrase) so that you don’t need to input anything when you log in to a server using this key pair. But for better security, a passphrase is suggested.</li><li>Copy your SSH public key into the server by <code>ssh-copy-id -i ~/.ssh/id_rsa.pub user_name@server_address</code> (change the path to the public key if you’ve saved it somewhere else). You’ll be prompted to enter <strong>your password at the server</strong>.</li><li>Log in to the server by <code>ssh user_name@server_address</code>. You should be able to log in without having to enter your password! If it doesn’t work, check the permission of the <code>~/.ssh</code> folder on your server. Only you should have write access to it. You can change its permission from your home folder by <code>chmod 700 .ssh</code>.</li></ol><h2 id="Avoid-file-descriptor-exhaustion"><a href="#Avoid-file-descriptor-exhaustion" class="headerlink" title="Avoid file descriptor exhaustion"></a>Avoid file descriptor exhaustion</h2><p>Running pipelines requires handle large numbers of concurrent connections require the ability to open many files (sockets, log files, etc.). The default ulimit values (especially for file descriptors) are often too low for research servers. Without adjusting these limits, File descriptor exhaustion can occur, resulting in errors like “Too many open files.”</p><p>Check the max allowed number of open files by</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ulimit -n</span><br></pre></td></tr></table></figure><p>Set it to a larger number:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ulimit -n 100000</span><br></pre></td></tr></table></figure><p>Or add the following line to <code>/etc/security/limits.conf</code>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*  -   nofile   100000</span><br></pre></td></tr></table></figure><h2 id="Change-the-default-plotting-settings-for-Matplotlib-and-Jupyter"><a href="#Change-the-default-plotting-settings-for-Matplotlib-and-Jupyter" class="headerlink" title="Change the default plotting settings for Matplotlib and Jupyter"></a>Change the default plotting settings for Matplotlib and Jupyter</h2><p>Many people explore and analyze data with the powerful combination of Matplotlib (along with Seaborn) and Jupyter Notebook&#x2F;Lab. This widely favored choice provides a flexible environment for data visualization. However, it’s important to note that the default settings of these tools may not always meet field-specific requirements. To address this, I have compiled a list of modifications that I personally introduced to the configuration files of Jupyter and Matplotlib. These changes allow for customization and tailoring of their default behaviors to suit individual needs better.</p><h3 id="Change-default-font-styles-in-Matplotlib"><a href="#Change-default-font-styles-in-Matplotlib" class="headerlink" title="Change default font styles in Matplotlib"></a>Change default font styles in Matplotlib</h3><p>Scientific publishers often have customized guidelines for figure fonts to ensure optimal print readability.They may specify requirements such as setting the typeface as Arial or Helvetica, with a minimum font size of 5 pt and a maximum size of 7 pt. Unfortunately, the default font styling in Matplotlib&#x2F;Seaborn is optimized for screen reading. As a result, many researchers manually adjust the font sizes of their generated figures in image editing software like Illustrator or Affinity Designer. This tedious process can be time-consuming and prone to error. By making necessary modifications to the configuration files of Jupyter and Matplotlib, we can ensure that our plots are in a publication-ready state from the very beginning, saving valuable time and effort.Here, I will show you how to change the default font size for matplotlib:</p><ol><li>Locate the configuration file for matplotlib by running the following code in a Python session:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="built_in">print</span>(matplotlib.matplotlib_fname())</span><br></pre></td></tr></table></figure></li><li>Open the configuration file, locate the default settings that you want to override.</li></ol><ul><li><code>figure.titlesize</code>: Font size of the figure title</li><li><code>axes.labelsize</code>: Font size for $x$ and $y$ labels</li><li><code>xtick.labelsize</code> and <code>ytick.labelsize</code>: Font size for the $x$ or $y$ ticks</li><li><code>legend.title_fontsize</code>: Font size for the title of the legend</li><li><code>legend.fontsize</code>: Font size for legends</li></ul><ol start="3"><li>If there’s a <code>#</code> right before the option, it means this option is commented and will not be considered by matplotlib. So to make it effective, remove the <code>#</code> first, then change the values to the ones you desired.</li><li>Save the file, and go create new figures.</li></ol><p>Here is the actual settings that I usually use:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">font.sans-serif: Arial, Helvetica, DejaVu Sans, Bitstream Vera Sans, Computer Modern Sans Serif, Lucida Grande, Verdana, Geneva, Lucid, Avant Garde, sans-serif</span><br><span class="line">font.size:             5     # default text sizes</span><br><span class="line">figure.titlesize:      7     # size of the figure title (``Figure.suptitle()``)</span><br><span class="line">figure.labelsize:      7     # size of the figure label (``Figure.sup[x|y]label()``)</span><br><span class="line">axes.titlesize:        7     # font size of the axes title</span><br><span class="line">axes.labelsize:        7     # font size of the x and y labels</span><br><span class="line">xtick.labelsize:       6     # font size of the x tick labels</span><br><span class="line">ytick.labelsize:       6     # font size of the y tick labels</span><br><span class="line">legend.title_fontsize: 7     # font size of legend tile</span><br><span class="line">legend.fontsize:       6     # font size of other text in the legend</span><br></pre></td></tr></table></figure><p>If you are looking for a one-time change, you can override these values in <code>RcParams</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.rc(<span class="string">&#x27;font&#x27;</span>, size=<span class="number">5</span>)          <span class="comment"># controls default text sizes</span></span><br><span class="line">plt.rc(<span class="string">&#x27;axes&#x27;</span>, titlesize=<span class="number">7</span>)     <span class="comment"># fontsize of the axes title</span></span><br><span class="line">plt.rc(<span class="string">&#x27;axes&#x27;</span>, labelsize=<span class="number">7</span>)     <span class="comment"># fontsize of the x and y labels</span></span><br><span class="line">plt.rc(<span class="string">&#x27;xtick&#x27;</span>, labelsize=<span class="number">6</span>)    <span class="comment"># fontsize of the tick labels</span></span><br><span class="line">plt.rc(<span class="string">&#x27;ytick&#x27;</span>, labelsize=<span class="number">6</span>)    <span class="comment"># fontsize of the tick labels</span></span><br><span class="line">plt.rc(<span class="string">&#x27;legend&#x27;</span>, fontsize=<span class="number">6</span>)    <span class="comment"># legend fontsize</span></span><br><span class="line">plt.rc(<span class="string">&#x27;figure&#x27;</span>, titlesize=<span class="number">7</span>)   <span class="comment"># fontsize of the figure title</span></span><br></pre></td></tr></table></figure><blockquote><p>Note: if you set the font sizes to 5~7 pts, you may also need to scale down the figure size. The default figure sizeis $6.4\times4.8 $ inches, I usually set the default as:</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">figure.figsize:     3.2, 2.4  # figure size in inches</span><br></pre></td></tr></table></figure><h3 id="Make-figures-in-Notebook-more-clear"><a href="#Make-figures-in-Notebook-more-clear" class="headerlink" title="Make figures in Notebook more clear"></a>Make figures in Notebook more clear</h3><p>For high-definition screen users, especially for people who are using Macbook and iMac, the inline figures shown up in Jupyter Notebook&#x2F; Lab can be very blurry, like the this one:</p><img src="/posts/setting-up-a-handy-research-environment-on-linux-servers/jupyter_default_output.png" class="" title="A blurry image generated with the default settings."><p>To solve this problem, you can execute the following command <strong>in the notebook</strong> that you want to get high-resolution figures:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%config InlineBackend.figure_format=<span class="string">&#x27;retina&#x27;</span></span><br></pre></td></tr></table></figure><p>Now output figures will be much more clear:</p><img src="/posts/setting-up-a-handy-research-environment-on-linux-servers/jupyter_high_resolution_output.png" class="" title="A high-resolution image generated with the modified settings."><p>The major drawback for the above method is that you have to execute it every time you create a new Notebook. If you want Notebooks to produce high-def figures by default, you’ll need to modify the configuration files for IPython (which Notebooks use it to run actual codes):</p><ol><li>Check if you’ve already had a configuration (<code>ipython_kernel_config.py</code>) for IPython created before. For Linux and MacOS users, the file is usually located at <code>~/.ipython/profile_default</code>, if you don’t know where it locates, you can use <code>ipython locate</code> to figure it out; if the file is not in this destination, you can run <code>ipython profile create</code> to create it.</li><li>Add <code>c.InlineBackend.figure_formats = [&quot;retina&quot;]</code> or <code>c.InlineBackend.figure_formats = [&quot;svg&quot;]</code> to the end of this file (<code>ipython_kernel_config.py</code>).</li><li>Kill your Jupyter Notebook &#x2F; Lab, and rerun it.</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Login-with-SSH-key&quot;&gt;&lt;a href=&quot;#Login-with-SSH-key&quot; class=&quot;headerlink&quot; title=&quot;Login with SSH key&quot;&gt;&lt;/a&gt;Login with SSH key&lt;/h2&gt;&lt;p&gt;Puttin</summary>
      
    
    
    
    <category term="posts" scheme="https://www.yaobio.com/posts/"/>
    
    
    <category term="technical_docs" scheme="https://www.yaobio.com/tags/technical-docs/"/>
    
    <category term="orientation" scheme="https://www.yaobio.com/tags/orientation/"/>
    
  </entry>
  
  <entry>
    <title>Securing Jupyter Notebooks by tracing modification histories</title>
    <link href="https://www.yaobio.com/posts/securing-jupyter-notebooks-by-tracing-modification-histories/"/>
    <id>https://www.yaobio.com/posts/securing-jupyter-notebooks-by-tracing-modification-histories/</id>
    <published>2020-05-15T19:45:21.000Z</published>
    <updated>2025-04-23T04:03:22.941Z</updated>
    
    <content type="html"><![CDATA[<p>Jupyter notebook&#x2F;lab is a fantastic tool for data analysis. I used it a lot in my daily research. But one of my habits makes me suffered a lot: I keep updating the same notebook for a long time, and to make the notebook neat, I always delete some of the cells, which are “redundant”&#x2F;“useless” for me at certain time points (or I just delete them by accident). So in many cases, I wondered whether I could add version control to notebooks, so that when something wrong happens, I can rollback to the status before specific events.</p><h2 id="Start-to-secure-your-notebooks"><a href="#Start-to-secure-your-notebooks" class="headerlink" title="Start to secure your notebooks"></a>Start to secure your notebooks</h2><p>The basic idea is to add a hook to Jupyter whenever it finishes saving a file (especially notebook), which will:</p><ol><li>generate a <code>git</code> repo in the folder where the notebook locates (if there isn’t);</li><li>copy the notebook to the repo (and convert notebook to python script);</li><li>add all changes to git;</li><li>commit modifications.</li></ol><p>Note: In many cases, we will focus in a short time and make a lot of modifications to notebooks. To avoid making too many commits, it would be better if we can randomly skip some modifications. In this post, let’s denote time span (in seconds) between last commit and current modification as $ts$, then the probability is $\min(1, \frac{ts}{3600})$ for the modified notebook to get committed.</p><p>Here are the steps to enable automatical backup (<strong>MUST install <code>git</code> first</strong>):</p><ol><li>Make sure you have a configuration file (<code>jupyter_notebook_config.py</code>) for Jupyter Notebook or Jupyter Lab. By default, it’s located at <code>~/.jupyter</code>. If are not sure, you can run <code>jupyter --config-dir</code>, which will tell you the file locates. If you don’t have any configuration files, generate one with <code>jupyter notebook --generate-config</code>;</li><li>Add the following codes to the beginning of the configuration file:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> ctime, time</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> choices</span><br><span class="line"><span class="keyword">from</span> subprocess <span class="keyword">import</span> check_call, CalledProcessError</span><br><span class="line"><span class="keyword">from</span> shutil <span class="keyword">import</span> copyfile</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">post_save</span>(<span class="params">model, os_path, contents_manager</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This function will do the following jobs:</span></span><br><span class="line"><span class="string">        1. creating a new folder named vcs (version control system)</span></span><br><span class="line"><span class="string">        2. converting jupyter notebooks to both python scripts and html files</span></span><br><span class="line"><span class="string">        3. moving converted files to vcs folder</span></span><br><span class="line"><span class="string">        4. keeping tracks with these files via git</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> model[<span class="string">&#x27;type&#x27;</span>] != <span class="string">&#x27;notebook&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> </span><br><span class="line">    logger = contents_manager.log</span><br><span class="line"></span><br><span class="line">    d, fname = os.path.split(os_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># skip new born notebooks</span></span><br><span class="line">    <span class="keyword">if</span> fname.startswith(<span class="string">&quot;Untitled&quot;</span>):</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    </span><br><span class="line">    vcs_d = os.path.join(d, <span class="string">&quot;vcs&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(vcs_d):</span><br><span class="line">        logger.info(<span class="string">&quot;Creating vcs folder at %s&quot;</span> % d)</span><br><span class="line">        os.makedirs(vcs_d)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        check_call([<span class="string">&#x27;git&#x27;</span>, <span class="string">&#x27;rev-parse&#x27;</span>], cwd=vcs_d)</span><br><span class="line">    <span class="keyword">except</span> CalledProcessError:</span><br><span class="line">        logger.info(<span class="string">&quot;Initiating git repo at %s&quot;</span> % d)</span><br><span class="line">        check_call([<span class="string">&#x27;git&#x27;</span>, <span class="string">&#x27;init&#x27;</span>], cwd=vcs_d)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_file_or_not</span>(<span class="params">file_name, folder</span>):</span><br><span class="line">        file_path = os.path.join(folder, file_name)</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(file_path):</span><br><span class="line">            ctime = os.path.getctime(file_path)</span><br><span class="line">            delta = time() - ctime</span><br><span class="line">            delta = delta <span class="keyword">if</span> delta &gt;= <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">            <span class="comment"># if file was modified in the past 1 hour, </span></span><br><span class="line">            <span class="comment"># then the new modification got 30% chance </span></span><br><span class="line">            <span class="comment"># to be saved</span></span><br><span class="line">            prob = delta / <span class="number">3600</span></span><br><span class="line">            prob = prob <span class="keyword">if</span> prob &lt;= <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">            save_or_not = choices((<span class="number">0</span>, <span class="number">1</span>), weights=(<span class="number">1</span>-prob, prob), k=<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> save_or_not:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    </span><br><span class="line">    rfn, ext = os.path.splitext(fname)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># in case notebook is not a python-based one (R,...)</span></span><br><span class="line">    script_ext = <span class="string">&quot;.py&quot;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os_path) <span class="keyword">as</span> fh:</span><br><span class="line">        tmp = json.load(fh)</span><br><span class="line">        script_ext = tmp[<span class="string">&quot;metadata&quot;</span>][<span class="string">&quot;language_info&quot;</span>][<span class="string">&quot;file_extension&quot;</span>]</span><br><span class="line">    script_fn = rfn+script_ext</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> add_file_or_not(script_fn, d):</span><br><span class="line">        check_call([<span class="string">&#x27;jupyter&#x27;</span>, <span class="string">&#x27;nbconvert&#x27;</span>, <span class="string">&#x27;--to&#x27;</span>, <span class="string">&#x27;script&#x27;</span>, fname], cwd=d)</span><br><span class="line">        os.replace(os.path.join(d, script_fn), os.path.join(d, <span class="string">&quot;vcs&quot;</span>, script_fn))</span><br><span class="line">        copyfile(os_path, os.path.join(d, <span class="string">&quot;vcs&quot;</span>, fname))</span><br><span class="line">    </span><br><span class="line">        check_call([<span class="string">&#x27;git&#x27;</span>, <span class="string">&#x27;add&#x27;</span>, script_fn, fname], cwd=vcs_d)</span><br><span class="line">        commit_msg = <span class="string">&#x27;Autobackup for %s (%s)&#x27;</span> % (fname, ctime())</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            check_call([<span class="string">&#x27;git&#x27;</span>, <span class="string">&#x27;commit&#x27;</span>, <span class="string">&#x27;-m&#x27;</span>, commit_msg], cwd=vcs_d)</span><br><span class="line">        <span class="keyword">except</span> CalledProcessError:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        logger.info(<span class="string">&quot;File too new to be traced.&quot;</span>)</span><br></pre></td></tr></table></figure></li><li>Search for <code>post_save_hook</code> in the configuration file; uncomment this line (if you see a <code>#</code> at the begining of the line, remove it), and change it to:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c.FileContentsManager.post_save_hook = post_save</span><br></pre></td></tr></table></figure></li><li>Restart Jupyter Lab or Notebook.</li></ol><h2 id="Restore-from-disasters"><a href="#Restore-from-disasters" class="headerlink" title="Restore from disasters"></a>Restore from disasters</h2><p>The easiest way to restore jupyter notebook from backups is add the <code>vcs</code> folder to a GUI for git (like Sourcetree) and export the version that you want to roll back to. But in case GUIs are not available, you can use the following commands.</p><p>Let’s assume the notebook is <code>a.ipynb</code>, and it locates at <code>/foo/bar</code>, then the git repo is located at <code>/foo/bar/vcs</code>, you can:</p><ol><li>use <code>git log --abbrev-commit</code> to see the history of modifications;<img src="/posts/securing-jupyter-notebooks-by-tracing-modification-histories/commit_ids.png" class="" title="Git commit ids"></li><li>choose the potential commit according to the time of submission, and record the commit id (red boxes above);</li><li>use <code>git show COMMIT_ID:FILE_NAME &gt; SAVE_TO</code> to export the committed file to SAVE_TO. If you want to export the records jupyter, then in this case, you can replace FILE_NAME as <code>a.ipynb</code>; but if you just want to export python codes, then you can replace FILE_NAME with <code>a.py</code>.</li></ol><h2 id="A-more-comprehensive-implementation"><a href="#A-more-comprehensive-implementation" class="headerlink" title="A more comprehensive implementation"></a>A more comprehensive implementation</h2><p>A better implementation of this function is to enable:</p><ol><li>backup&#x2F;version control only in specific folders instead of everywhere;</li><li>tracing other non-notebook files, like Python&#x2F;R scripts;</li><li>allowing pushing changes to remote repositories.</li></ol><p>So by introducing the following two changes, the above three goals can be meet smoothly:</p><ol><li>Add a configuration file (<code>backup.conf</code>) in the folder that you want to enable version control, and below is a template for this file<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[repo]</span><br><span class="line">local_repo_folder = vcs</span><br><span class="line">remote_repo = </span><br><span class="line"></span><br><span class="line">[backup]</span><br><span class="line">backup_notebooks = no</span><br><span class="line">backup_notebook_converted_scripts = yes</span><br><span class="line">backup_by_filetypes = yes</span><br><span class="line">backup_filetypes = .py|.R</span><br></pre></td></tr></table></figure></li></ol><p>The keys in the configuration file stand for:</p><ul><li><code>local_repo_folder</code>: name of the local folder that the git repo will be located;</li><li><code>remote_repo</code>: remote address for the repo, leave it as blank if you don’t want to push these changes to other servers;</li><li><code>backup_notebooks</code>: set it to <code>yes</code> to enable tracing Notebooks in <code>.ipynb</code> format. <em>NOTE</em>: if your notebook contains a lot images or significant amount of outputs, then you may want to set it as <code>no</code> to save some space;</li><li><code>backup_notebook_converted_scripts</code>: set it to <code>yes</code> to enable tracing Notebooks in <code>.py</code> format or any other format that the notebook is based-on;</li><li><code>backup_by_filetypes</code> and <code>backup_filetypes</code>: set the first one to be <code>yes</code> to enable tracing other text files with extensions in <code>backup_filetypes</code>. In this example, all files ending with <code>.py</code> and <code>.R</code> will be traced (case-insensitive).</li></ul><ol start="2"><li>Modify <code>post_save</code>:<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> configparser <span class="keyword">import</span> ConfigParser</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> ctime, time</span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> choices</span><br><span class="line"><span class="keyword">from</span> subprocess <span class="keyword">import</span> check_call, CalledProcessError</span><br><span class="line"><span class="keyword">from</span> shutil <span class="keyword">import</span> copyfile</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">post_save</span>(<span class="params">model, os_path, contents_manager</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This function will do the following jobs:</span></span><br><span class="line"><span class="string">        1. creating a new folder named vcs (version control system)</span></span><br><span class="line"><span class="string">        2. converting jupyter notebooks to both python scripts and html files</span></span><br><span class="line"><span class="string">        3. moving converted files to vcs folder</span></span><br><span class="line"><span class="string">        4. keeping tracks with these files via git</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    d, fname = os.path.split(os_path)</span><br><span class="line">    conf_file = os.path.join(d, <span class="string">&quot;backup.conf&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(conf_file):</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    config = ConfigParser()</span><br><span class="line">    config.optionxform = <span class="built_in">str</span></span><br><span class="line">    config.read(conf_file)</span><br><span class="line">    supported_files = <span class="built_in">set</span>([ft.lower() <span class="keyword">for</span> ft <span class="keyword">in</span> config.get(<span class="string">&quot;backup&quot;</span>, <span class="string">&quot;backup_filetypes&quot;</span>).split(<span class="string">&quot;|&quot;</span>)])</span><br><span class="line">    logger = contents_manager.log</span><br><span class="line"></span><br><span class="line">    vcs_d = os.path.join(d, config.get(<span class="string">&quot;repo&quot;</span>, <span class="string">&quot;local_repo_folder&quot;</span>))</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(vcs_d):</span><br><span class="line">        logger.info(<span class="string">&quot;Creating vcs folder at %s&quot;</span> % d)</span><br><span class="line">        os.makedirs(vcs_d)</span><br><span class="line">    </span><br><span class="line">    repo_init = <span class="number">0</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        check_call([<span class="string">&#x27;git&#x27;</span>, <span class="string">&#x27;rev-parse&#x27;</span>], cwd=vcs_d)</span><br><span class="line">    <span class="keyword">except</span> CalledProcessError:</span><br><span class="line">        logger.info(<span class="string">&quot;Initiating git repo at %s&quot;</span> % d)</span><br><span class="line">        check_call([<span class="string">&#x27;git&#x27;</span>, <span class="string">&#x27;init&#x27;</span>], cwd=vcs_d)</span><br><span class="line">        <span class="keyword">if</span> config.get(<span class="string">&quot;repo&quot;</span>, <span class="string">&quot;remote_repo&quot;</span>) != <span class="string">&quot;&quot;</span>:</span><br><span class="line">            check_call([<span class="string">&#x27;git&#x27;</span>, <span class="string">&#x27;remote&#x27;</span>, <span class="string">&#x27;add&#x27;</span>, <span class="string">&#x27;origin&#x27;</span>, config.get(<span class="string">&quot;repo&quot;</span>, <span class="string">&quot;remote_repo&quot;</span>)], cwd=vcs_d)</span><br><span class="line">            repo_init = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_file_or_not</span>(<span class="params">file_name, folder</span>):</span><br><span class="line">        file_path = os.path.join(folder, file_name)</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(file_path):</span><br><span class="line">            ctime = os.path.getctime(file_path)</span><br><span class="line">            delta = time() - ctime</span><br><span class="line">            delta = delta <span class="keyword">if</span> delta &gt;= <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">            <span class="comment"># if file was modified in the past 1 hour, </span></span><br><span class="line">            <span class="comment"># then the new modification got 30% chance </span></span><br><span class="line">            <span class="comment"># to be saved</span></span><br><span class="line">            prob = delta / <span class="number">3600</span></span><br><span class="line">            prob = prob <span class="keyword">if</span> prob &lt;= <span class="number">1</span> <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">            save_or_not = choices((<span class="number">0</span>, <span class="number">1</span>), weights=(<span class="number">1</span>-prob, prob), k=<span class="number">1</span>)[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">if</span> save_or_not:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    rfn, ext = os.path.splitext(fname)</span><br><span class="line">    lext = ext.lower()</span><br><span class="line">    updated_files = []</span><br><span class="line">    <span class="keyword">if</span> model[<span class="string">&quot;type&quot;</span>] == <span class="string">&quot;notebook&quot;</span>:</span><br><span class="line">        <span class="comment"># skip new born notebooks</span></span><br><span class="line">        <span class="keyword">if</span> fname.startswith(<span class="string">&quot;Untitled&quot;</span>):</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># in case notebook is not a python-based one (R,...)</span></span><br><span class="line">        script_ext = <span class="string">&quot;.py&quot;</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(os_path) <span class="keyword">as</span> fh:</span><br><span class="line">            tmp = json.load(fh)</span><br><span class="line">            script_ext = tmp[<span class="string">&quot;metadata&quot;</span>][<span class="string">&quot;language_info&quot;</span>][<span class="string">&quot;file_extension&quot;</span>]</span><br><span class="line">        script_fn = rfn + script_ext</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> add_file_or_not(script_fn, d):</span><br><span class="line">            <span class="keyword">if</span> config.get(<span class="string">&quot;backup&quot;</span>, <span class="string">&quot;backup_notebooks&quot;</span>) == <span class="string">&quot;yes&quot;</span>:</span><br><span class="line">                copyfile(os_path, os.path.join(vcs_d, fname))</span><br><span class="line">                updated_files.append(fname)</span><br><span class="line">            <span class="keyword">if</span> config.get(<span class="string">&quot;backup&quot;</span>, <span class="string">&quot;backup_notebook_converted_scripts&quot;</span>) == <span class="string">&quot;yes&quot;</span>:</span><br><span class="line">                check_call([<span class="string">&#x27;jupyter&#x27;</span>, <span class="string">&#x27;nbconvert&#x27;</span>, <span class="string">&#x27;--to&#x27;</span>, <span class="string">&#x27;script&#x27;</span>, fname], cwd=d)</span><br><span class="line">                os.replace(os.path.join(d, script_fn), os.path.join(vcs_d, script_fn))</span><br><span class="line">                updated_files.append(script_fn)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            logger.info(<span class="string">&quot;File too new to be traced.&quot;</span>)</span><br><span class="line">    <span class="keyword">elif</span> config.get(<span class="string">&quot;backup&quot;</span>, <span class="string">&quot;backup_by_filetypes&quot;</span>) == <span class="string">&quot;yes&quot;</span> <span class="keyword">and</span> lext <span class="keyword">in</span> supported_files:</span><br><span class="line">        copyfile(os_path, os.path.join(vcs_d, fname))</span><br><span class="line">        updated_files.append(fname)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(updated_files) &gt; <span class="number">0</span>:</span><br><span class="line">        cmd = [<span class="string">&#x27;git&#x27;</span>, <span class="string">&#x27;add&#x27;</span>]</span><br><span class="line">        cmd.extend(updated_files)</span><br><span class="line">        check_call(cmd, cwd=vcs_d)</span><br><span class="line">        commit_msg = <span class="string">&#x27;Autobackup for %s (%s)&#x27;</span> % (fname, ctime())</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            check_call([<span class="string">&#x27;git&#x27;</span>, <span class="string">&#x27;commit&#x27;</span>, <span class="string">&#x27;-m&#x27;</span>, commit_msg], cwd=vcs_d)</span><br><span class="line">            <span class="keyword">if</span> config.get(<span class="string">&quot;repo&quot;</span>, <span class="string">&quot;remote_repo&quot;</span>) != <span class="string">&quot;&quot;</span>:</span><br><span class="line">                <span class="keyword">if</span> repo_init:</span><br><span class="line">                    check_call([<span class="string">&#x27;git&#x27;</span>, <span class="string">&#x27;push&#x27;</span>, <span class="string">&#x27;--set-upstream&#x27;</span>, <span class="string">&#x27;origin&#x27;</span>, <span class="string">&#x27;master&#x27;</span>], cwd=vcs_d)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    check_call([<span class="string">&#x27;git&#x27;</span>, <span class="string">&#x27;push&#x27;</span>], cwd=vcs_d)</span><br><span class="line">        <span class="keyword">except</span> CalledProcessError <span class="keyword">as</span> e:</span><br><span class="line">            logger.info(e)</span><br></pre></td></tr></table></figure></li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul><li><a href="https://github.com/jupyterhub/jupyterhub/issues/1412">A closed issue from Jupyter Hub</a></li><li><a href="https://nbconvert.readthedocs.io/en/latest/">nbconvert</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Jupyter notebook&amp;#x2F;lab is a fantastic tool for data analysis. I used it a lot in my daily research. But one of my habits makes me suff</summary>
      
    
    
    
    <category term="posts" scheme="https://www.yaobio.com/posts/"/>
    
    
    <category term="technical_docs" scheme="https://www.yaobio.com/tags/technical-docs/"/>
    
  </entry>
  
  <entry>
    <title>Demystifying NGS Quality Reports: Case Studies</title>
    <link href="https://www.yaobio.com/posts/demystifying-ngs-quality-reports-case-studies/"/>
    <id>https://www.yaobio.com/posts/demystifying-ngs-quality-reports-case-studies/</id>
    <published>2020-05-10T09:11:34.000Z</published>
    <updated>2025-04-23T04:03:22.936Z</updated>
    
    <content type="html"><![CDATA[<p>Unlocking the secrets hidden in Next-Generation Sequencing (NGS) data is an exciting journey, but it’s important to ensure that the data quality is top-notch. That’s where powerful tools like FastQC come in! With FastQC, you can easily perform quality checks and ensure that your data is of the highest caliber. In this post, we delve into real-life cases where diagnostic plots from FastQC have helped unravel complex problems and bring clarity to our analysis. Join me on this thrilling adventure!</p><p><em>The arrangement of this post is based on the output from FastQC, but the criteria or cases mentioned here should also be applicable to similar measurements produced by other tools.</em></p><h2 id="Per-Base-Sequence-Content"><a href="#Per-Base-Sequence-Content" class="headerlink" title="Per Base Sequence Content"></a>Per Base Sequence Content</h2><p><a href="#Per-Base-Sequence-Content"><code>Per Base Sequence Content</code></a> stacks together all sequences in a fastq file and calculates the frequency of the four normal DNA bases (A&#x2F;T&#x2F;C&#x2F;G) called for each base position.In a random or unbiased library, the bases should follow a random distribution of A&#x2F;T&#x2F;C&#x2F;G, so the lines in the plot should be parallel to each other (around 25%). However, the actual distributions may have some fluctuations, depending on the overall number of bases in the genome and the capturing bias from the assay. Nevertheless, in most cases, the lines should be approximately parallel.</p><p><a href="#Per-Base-Sequence-Content"><code>Per Base Sequence Content</code></a> can be used to find:</p><ul><li>biased fragments, like:<ul><li><strong>untrimmed barcodes</strong>. For demultiplexed libraries, if there are untrimmed barcodes, then because of the fixed sequences, you would observe sharp peaks at the beginnings or ends of reads. Below is an example showing that $5^\prime$ barcodes (<em>TGGTCAC</em>) are not trimmed:  <img src="/posts/demystifying-ngs-quality-reports-case-studies/barcode_TGGTCAC.png" class="" title="Per base sequence content suggests the existence of $5^prime$ barcode TGGTCAC"></li><li><strong>template switching oligo</strong>. In cases like this, you can observe characteristic trinucleotide <em>GGG</em> or <em>CCC</em> near the beginning of reads.  <img src="/posts/demystifying-ngs-quality-reports-case-studies/ts.png" class="" title="Template switching oligos TATAGGG"></li></ul></li><li><a href="#Overrepresented-Sequences">overrepresented sequences</a>, like adapter dimers or rRNAs.</li></ul><p>Safelist:</p><ul><li>For libraries treated with sodium bisulfite, which will convert C to T, it’s normal to observe a low percent of Cs.</li></ul><h2 id="Adapter-Content"><a href="#Adapter-Content" class="headerlink" title="Adapter Content"></a>Adapter Content</h2><p>For libraries where a significant amount of the inserts are shorter than the sequencing length,adapters are likely to be incorporated in final reads. This is very common for libraries enriching for short&#x2F;smallRNAs, like PRO-cap, PRO-seq, etc. The <a href="#Adapter-Content"><code>Adapter Content</code></a> module compares reads with commonly used adapter sequences and plots the enrichment. Adapter sequences may greatly affect on sequencing alignments, so if you see warnings in this section, you may need to trim adapters with <code>cutadapt</code>, <code>fastp</code>, or any other tool you like. In the following example, the <a href="#Adapter-Content"><code>Adapter Content</code></a> module detects theexistence of <em>Nextera Transposase Sequence</em> (the risen black line).</p><img src="/posts/demystifying-ngs-quality-reports-case-studies/adapter.png" class="" title="Untrimmed adapters"><h2 id="Overrepresented-Sequences"><a href="#Overrepresented-Sequences" class="headerlink" title="Overrepresented Sequences"></a>Overrepresented Sequences</h2><p>A sequencing library typically consists of a diverse mixture of DNA or RNA molecules, and the presence of frequently occurring specific sequences can indicate an abnormality.</p><h3 id="Possibility-1-Adapters"><a href="#Possibility-1-Adapters" class="headerlink" title="Possibility 1: Adapters"></a>Possibility 1: Adapters</h3><p>One possible cause for warnings or errors from this module is the presence of adapters.For example, people usually use a customized $3^\prime$ cloning adapter, <em>CTGTAGGCACCATCAAT</em>,to generate <a href="https://en.wikipedia.org/wiki/Ribosome_profiling">Ribo-seq</a> libraries. This sequence is not included in the known-adapter list in FastQC,so the <a href="#Adapter-Content"><code>Adapter Content</code></a> module <strong>cannot</strong> detect the existence of adapters,but the <a href="#Overrepresented-Sequences"><code>Overrepresented Sequences</code></a> module catches a lot of hits.The following screenshot shows the top 12 overrepresented sequences from a Ribo-seq library(<a href="https://www.ncbi.nlm.nih.gov/sra/?term=SRR942878">SRR942878</a>), and the adapter sequence is highlighted for clarity.</p><img src="/posts/demystifying-ngs-quality-reports-case-studies/overrepresented_sequences_CTGTAGGCACCATCA.png" class="" width="773" title="Overrepresented sequence report for sequence library SRR942878."><p>In practical applications, adapters may not be immediately visible in a table of many sequences. To identify potential adapters, I often choose a few overrepresented sequences and use the Smith-Waterman alignment algorithm to find adapter candidates. Typically, adapters appear as aligned contigs near the ends of sequences. For instance, when running the SW alignment on the first two hits in the table above, the adapter <code>CTGTAGGCACCATCAAT</code> is clearly visible:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CCGGCTAGCTCAGTCGGTAGAGCATGAGCTGTAGGCACCATCAATTCG</span><br><span class="line">CCAGCTAGCA-ATTGGGTGTAGC-----CTGTAGGCACCATCAATTCG</span><br></pre></td></tr></table></figure><p>You can run the Smith-Waterman algorithm <a href="bioseq.html">here</a>.</p><h3 id="Possibility-2-rRNAs-or-Other-“Contamination”"><a href="#Possibility-2-rRNAs-or-Other-“Contamination”" class="headerlink" title="Possibility 2: rRNAs or Other “Contamination”"></a>Possibility 2: rRNAs or Other “Contamination”</h3><p>What if the overrepresented sequences don’t match the typical adapter patterns? In some cases, these sequences may actually be “contamination” from ribosomal RNAs or other sources. One way to test this possibility is to run a <a href="https://blast.ncbi.nlm.nih.gov/">BLAST</a> search on the sequences. For example, here are the top overrepresented sequences for <a href="https://www.ncbi.nlm.nih.gov/sra/?term=SRR2960998">another sequencing library</a>:</p><img src="/posts/demystifying-ngs-quality-reports-case-studies/rRNA_SRR2960998.png" class="" width="977" title="Overrepresented sequence report for sequence library SRR942878."><p>When running BLAST on some of these overrepresented sequences, you can see that they match with ribosomal RNAs. </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Chain 2, 18S rRNA</span><br><span class="line">Sequence ID: 7WTT_2 Length: 1873 Number of Matches: 1</span><br><span class="line">Range 1: 131 to 182</span><br><span class="line">Alignment statistics for match #1</span><br><span class="line">ScoreExpectIdentitiesGapsStrand</span><br><span class="line">97.1 bits(52)1e-1652/52(100%)0/52(0%)Plus/Minus</span><br><span class="line">Query  1    GTCGGCATGTATTAGCTCTAGAATTACCACAGTTATCCAAGTAGGAGAGGAG  52</span><br><span class="line">            ||||||||||||||||||||||||||||||||||||||||||||||||||||</span><br><span class="line">Sbjct  182  GTCGGCATGTATTAGCTCTAGAATTACCACAGTTATCCAAGTAGGAGAGGAG  131</span><br></pre></td></tr></table></figure><p>If this is the case, you can align the entire library to ribosomal RNAs first, then do a second round of alignmentwith reads that cannot be aligned in the first round. This ensures you are left with high-quality reads for downstream analysis.</p><h2 id="Per-Base-Sequence-Quality"><a href="#Per-Base-Sequence-Quality" class="headerlink" title="Per Base Sequence Quality"></a>Per Base Sequence Quality</h2><p>No cases yet.</p><h2 id="Per-Sequence-Quality-Scores"><a href="#Per-Sequence-Quality-Scores" class="headerlink" title="Per Sequence Quality Scores"></a>Per Sequence Quality Scores</h2><p>No cases yet.</p><h2 id="Per-Sequence-GC-Content"><a href="#Per-Sequence-GC-Content" class="headerlink" title="Per Sequence GC Content"></a>Per Sequence GC Content</h2><p>No cases yet.</p><h2 id="Per-Base-N-Content"><a href="#Per-Base-N-Content" class="headerlink" title="Per Base N Content"></a>Per Base N Content</h2><p>No cases yet.</p><h2 id="Sequence-Length-Distribution"><a href="#Sequence-Length-Distribution" class="headerlink" title="Sequence Length Distribution"></a>Sequence Length Distribution</h2><p>No cases yet.</p><h2 id="Sequence-Duplication-Levels"><a href="#Sequence-Duplication-Levels" class="headerlink" title="Sequence Duplication Levels"></a>Sequence Duplication Levels</h2><p>No cases yet.</p><p>Reference:<a href="http://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/">FastQC manual</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;Unlocking the secrets hidden in Next-Generation Sequencing (NGS) data is an exciting journey, 
but it’s important to ensure that the data quality is top-notch. That’s where powerful tools like FastQC come in! 
With FastQC, you can easily perform quality checks and ensure that your data is of the highest caliber. 
In this post, we delve into real-life cases where diagnostic plots from FastQC have helped unravel 
complex problems and bring clarity to our analysis. Join me on this thrilling adventure!&lt;/p&gt;</summary>
    
    
    
    <category term="posts" scheme="https://www.yaobio.com/posts/"/>
    
    
    <category term="technical_docs" scheme="https://www.yaobio.com/tags/technical-docs/"/>
    
  </entry>
  
  <entry>
    <title>File templates for writing codes</title>
    <link href="https://www.yaobio.com/posts/file-templates-for-writing-codes/"/>
    <id>https://www.yaobio.com/posts/file-templates-for-writing-codes/</id>
    <published>2020-04-29T17:17:37.000Z</published>
    <updated>2025-04-23T04:03:22.945Z</updated>
    
    <content type="html"><![CDATA[<p>Some good templates for writing codes (<code>shell</code>, <code>python</code>, etc) were provided in this post.</p><h1 id="Shell-script"><a href="#Shell-script" class="headerlink" title="Shell script"></a>Shell script</h1><ol><li>Specify shebang in the beginning of shell script, which tells the loader which interpreter should be called, this helps as different bashes have different syntaxes. In the following case, shebang line tells the loader to use user-preferred bash.</li><li>Add error handling: <code>set -o errexit;</code>, this will abort the execution of current shell script, if any command fails to be executed. When something wrong happens, this strategy helps you to locate the problem quickly, as traceback information will be highlighted at the line that the error actually occurs.</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/usr/bin/env bash</span></span><br><span class="line">set -o errexit;</span><br></pre></td></tr></table></figure><h1 id="Python-script"><a href="#Python-script" class="headerlink" title="Python script"></a>Python script</h1><ol><li>Specify shebang in the beginning of python scripts, if you want to run the script directly <code>./one_script.py</code>.</li><li>Define Python source code encodings so that non-Latin characters will not disrupt the execution of a script.</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding=utf-8</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Some good templates for writing codes (&lt;code&gt;shell&lt;/code&gt;, &lt;code&gt;python&lt;/code&gt;, etc) were provided in this post.&lt;/p&gt;
&lt;h1 id=&quot;Shell-script</summary>
      
    
    
    
    <category term="posts" scheme="https://www.yaobio.com/posts/"/>
    
    
    <category term="best_practice" scheme="https://www.yaobio.com/tags/best-practice/"/>
    
  </entry>
  
  <entry>
    <title>Collection of commonly used references in bioinformatic analysis</title>
    <link href="https://www.yaobio.com/posts/collection-of-commonly-used-references-in-bioinformatic-analysis/"/>
    <id>https://www.yaobio.com/posts/collection-of-commonly-used-references-in-bioinformatic-analysis/</id>
    <published>2020-04-22T17:41:22.000Z</published>
    <updated>2025-04-23T04:03:22.945Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Human"><a href="#Human" class="headerlink" title="Human"></a>Human</h1><p>Currently, there are two widely used releases GRCh38 (hg38) and GRCh37 (hg19).</p><h2 id="GRCh38-hg38"><a href="#GRCh38-hg38" class="headerlink" title="GRCh38 (hg38)"></a>GRCh38 (hg38)</h2><h3 id="Sequences"><a href="#Sequences" class="headerlink" title="Sequences"></a>Sequences</h3><ul><li>File name: <code>GRCh38_no_alt_analysis_set_GCA_000001405.15.fa.gz</code> (MD5 checksum: <code>a08035b6a6e31780e96a34008ff21bd6</code>)</li><li>Local path: <em>&#x2F;References&#x2F;Sequences&#x2F;human&#x2F;hg38&#x2F;GRCh38_no_alt_analysis_set_GCA_000001405.15.fa.gz</em></li><li>Remote backup: <a href="https://osf.io/qyznb/">OSF</a></li><li>Description: This file contains sequences for the following:<ol><li>chromosomes from the GRCh38 Primary Assembly (PA);</li><li>mitochondrial genome from the GRCh38 non-nuclear assembly;</li><li>unlocalized scaffolds from PA;</li><li>unplaced scaffolds from PA;</li><li>Epstein-Barr virus (EBV) sequence.</li></ol></li><li>Recipe:<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://www.encodeproject.org/files/GRCh38_no_alt_analysis_set_GCA_000001405.15/@@download/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta.gz;</span><br></pre></td></tr></table></figure></li></ul><h3 id="Annotations"><a href="#Annotations" class="headerlink" title="Annotations"></a>Annotations</h3><h4 id="Gene-annotations"><a href="#Gene-annotations" class="headerlink" title="Gene annotations"></a>Gene annotations</h4><p>There are three major releases of gene annotations for <em>Homo sapiens</em>:</p><ul><li>GENCODE&#x2F;Ensembl annotation: The GENCODE annotation is made from Ensembl annotation, so gene annotations are the same in both releases. The only exception is that the genes which are common to the human chromosome X and Y PAR regions can be found twice in the GENCODE GTF, while they are shown only for chromosome X in the Ensembl file. Gene &#x2F; transcripts IDs are the same in both releases except for annotations is the PAR regions. Comparing to other annotations, GENCODE annotation provides higher coverage among non-coding regions.</li><li>RefSeq Gene (RefGene): Annotations for well-characterized genes (mostly protein-coding genes). Projects like Gene Ontology, KEGG and MSigDB (Molecular Signatures Database, gene sets for GSEA) use this annotation as gene identifiers. So RefGene maybe the preferred annotation if you want to do enrichment analysis with GO&#x2F;KEGG&#x2F;GSEA.</li><li>UCSC Known genes: Automatically generated annotations (based on protein sequences from Swiss-Prot), mostly for protein-coding genes.</li></ul><h5 id="GENCODE"><a href="#GENCODE" class="headerlink" title="GENCODE"></a>GENCODE</h5><ul><li><p>File name: <code>gencode.v24.annotation.gtf.gz</code> (MD5 checksum: <code>17395005bb4471605db62042b992893e</code>)</p></li><li><p>Local path: <em>&#x2F;References&#x2F;Annotations&#x2F;human&#x2F;hg38&#x2F;gencode.v24.annotation.gtf.gz</em></p></li><li><p>Remote backup: <a href="https://osf.io/v4rn9/">OSF</a></p></li><li><p>Description: GENCODE comprehensive annotation release 24. Downloaded from GENCODE’s website.</p></li><li><p>Recipe: </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_24/gencode.v24.annotation.gtf.gz</span><br></pre></td></tr></table></figure></li><li><p>File name: <code>gencode.v24.segmented.tssup1kb.bed.gz</code> (MD5 checksum: <code>972a57431c6209667d5aac41bbb01ebd</code>)</p></li><li><p>Local path: <em>&#x2F;References&#x2F;Annotations&#x2F;human&#x2F;hg38&#x2F;gencode.v24.segmented.tss*<em>up1kb</em></em>.bed.gz*</p></li><li><p>Remote backup: <a href="https://osf.io/ptde7/">OSF</a></p></li><li><p>Description: Genomic segmentations (promoter, 5_UTR, exon, intron, 3_UTR, and intergenic region) based on GENCODE v24, promoters were defined as upstream 1kb of TSSs (transcripts).</p></li><li><p>Recipe: </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">promoters <span class="keyword">for</span> protein-coding genes</span></span><br><span class="line">zcat gencode.v24.annotation.gtf.gz | \</span><br><span class="line">    awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;&#125; $3==&quot;transcript&quot; &#123;print $1,$4-1,$5,$18,&quot;promoter&quot;,$7,$14&#125;&#x27; | tr -d &#x27;&quot;;&#x27; | \</span><br><span class="line">    awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;;FS=&quot;\t&quot;&#125;&#123;if ($7==&quot;protein_coding&quot;)&#123;print $1,$2,$3,$4,$5,$6,$2,$3,&quot;102,194,165&quot;&#125;&#125;&#x27; | \</span><br><span class="line">    bedtools flank -i - -g hg38.genome -l 1000 -r 0 -s &gt; promoters_1kb_p.bed</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">promoters <span class="keyword">for</span> non-protein-coding genes</span></span><br><span class="line">zcat gencode.v24.annotation.gtf.gz | \</span><br><span class="line">    awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;&#125; $3==&quot;transcript&quot; &#123;print $1,$4-1,$5,$18,&quot;promoter(NP)&quot;,$7,$14&#125;&#x27; | tr -d &#x27;&quot;;&#x27; | \</span><br><span class="line">    awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;;FS=&quot;\t&quot;&#125;&#123;if ($7!=&quot;protein_coding&quot;)&#123;print $1,$2,$3,$4,$5,$6,$2,$3,&quot;102,194,165&quot;&#125;&#125;&#x27; | \</span><br><span class="line">    bedtools flank -i - -g hg38.genome -l 1000 -r 0 -s &gt; promoters_1kb_np.bed</span><br></pre></td></tr></table></figure></li><li><p>File name: <code>gencode.v24.segmented.tssflanking500b.bed.gz</code></p></li><li><p>Local Path: <em>&#x2F;References&#x2F;Anotations&#x2F;human&#x2F;hg38&#x2F;gencode.v24.segmented.tss*<em>flanking500b</em></em>.bed.gz*</p></li><li><p>Remote backup: <a href="https://osf.io/4ht6c/">OSF</a></p></li><li><p>Description: Genomic segmentations based on GENCODE v24, promoters were defined as TSS $\pm$ 500bp (transcripts). (<code>2e624c3bc2330beb81464558ead1a11e</code>)</p></li><li><p>Recipe:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">promoters <span class="keyword">for</span> protein-coding genes</span></span><br><span class="line">zcat gencode.v24.annotation.gtf.gz | \</span><br><span class="line">    awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;&#125; $3==&quot;transcript&quot; &#123;print $1,$4-1,$5,$18,&quot;promoter&quot;,$7,$14&#125;&#x27; | tr -d &#x27;&quot;;&#x27; | \</span><br><span class="line">    awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;;FS=&quot;\t&quot;&#125;&#123;if ($7==&quot;protein_coding&quot;)&#123;print $1,$2,$3,$4,$5,$6,$2,$3,&quot;102,194,165&quot;&#125;&#125;&#x27; | \</span><br><span class="line">    bedtools flank -i - -g hg38.genome -l 500 -r 0 -s | \</span><br><span class="line">    bedtools slop -i - -g hg38.genome -l 0 -r 500 -s &gt; promoters_500bp.bed</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">promoters <span class="keyword">for</span> non-protein-coding genes</span></span><br><span class="line">zcat gencode.v24.annotation.gtf.gz | \</span><br><span class="line">    awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;&#125; $3==&quot;transcript&quot; &#123;print $1,$4-1,$5,$18,&quot;promoter(NP)&quot;,$7,$14&#125;&#x27; | tr -d &#x27;&quot;;&#x27; | \</span><br><span class="line">    awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;;FS=&quot;\t&quot;&#125;&#123;if ($7!=&quot;protein_coding&quot;)&#123;print $1,$2,$3,$4,$5,$6,$2,$3,&quot;102,194,165&quot;&#125;&#125;&#x27; | \</span><br><span class="line">    bedtools flank -i - -g hg38.genome -l 500 -r 0 -s \</span><br><span class="line">    bedtools slop -i - -g hg38.genome -l 0 -r 500 -s &gt; np_promoters_500bp.bed</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">intergenic</span></span><br><span class="line">zcat gencode.v24.annotation.gtf.gz | \</span><br><span class="line">    awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;&#125; $3==&quot;gene&quot; &#123;print $1,$4-1,$5,$10,$16,$7&#125;&#x27; | \</span><br><span class="line">    tr -d &#x27;&quot;;&#x27; | \</span><br><span class="line">    bedtools slop -i - -g hg38.genome -l 500 -r 0 -s | \</span><br><span class="line">    sortBed -g ../hg38.genome | \</span><br><span class="line">    bedtools complement -i stdin -g ../hg38.genome | \</span><br><span class="line">    awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;;FS=&quot;\t&quot;&#125;&#123;print $1,$2,$3,&quot;.&quot;,&quot;intergenic&quot;,&quot;.&quot;,$2,$3,&quot;141,160,203&quot;&#125;&#x27; &gt; intergenic_500bp.bed</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">exons</span></span><br><span class="line">zcat gencode.v24.annotation.gtf.gz | \</span><br><span class="line">    awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;;&#125; $3==&quot;exon&quot; &#123;print $1,$4-1,$5,$18,&quot;exon&quot;,$7&#125;&#x27; | \</span><br><span class="line">    tr -d &#x27;&quot;;&#x27; | \</span><br><span class="line">    sortBed -g ../hg38.genome | \</span><br><span class="line">    mergeBed -i - -c 4,5,6 -o distinct,distinct,distinct -s | \</span><br><span class="line">    awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;;FS=&quot;\t&quot;&#125;&#123;print $1,$2,$3,$4,$5,$6,$2,$3,&quot;231,138,195&quot;&#125;&#x27; &gt; exons.bed</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">introns</span></span><br><span class="line">zcat gencode.v24.annotation.gtf.gz | \</span><br><span class="line">    awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;;&#125; $3==&quot;gene&quot; &#123;print $1,$4-1,$5,$16,&quot;intron&quot;,$7&#125;&#x27; | \</span><br><span class="line">    tr -d &#x27;&quot;;&#x27; | \</span><br><span class="line">    sortBed -g ../hg38.genome | \</span><br><span class="line">    subtractBed -a stdin -b exons.bed | \</span><br><span class="line">    awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;;FS=&quot;\t&quot;&#125;&#123;print $1,$2,$3,$4,$5,$6,$2,$3,&quot;255,217,47&quot;&#125;&#x27; &gt; introns.bed</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">UTR, perl script from https://davetang.org/muse/2012/09/12/gencode/</span></span><br><span class="line">get_35_utr.pl gencode.v24.annotation.gtf.gz | \</span><br><span class="line">    awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;;FS=&quot;\t&quot;&#125;&#123;if ($5==&quot;3_UTR&quot;)&#123;print $1,$2,$3,$4,$5,$6,$2,$3,&quot;166,216,84&quot;&#125;else&#123;print $1,$2,$3,$4,$5,$6,$2,$3,&quot;252,141,98&quot;&#125;&#125;&#x27; &gt; utr.bed</span><br><span class="line"></span><br><span class="line">cat intergenic_500bp.bed promoters_500bp.bed np_promoters_500bp.bed utr.bed introns.bed exons.bed | sort -k1,1 -k2,2n | bgzip &gt; gencode.v24.segmented.tssflanking500b.bed.gz</span><br></pre></td></tr></table></figure></li></ul><h5 id="RefGene"><a href="#RefGene" class="headerlink" title="RefGene"></a>RefGene</h5><ul><li>File name: <code>refseq.ver109.20190125.annotation.gtf.gz</code> (MD5 checksum: <code>848813de5b516e0f328046ef9c931091</code>)</li><li>Local path: <em>&#x2F;References&#x2F;Annotations&#x2F;human&#x2F;hg38&#x2F;refseq.ver109.20190125.annotation.gtf.gz</em></li><li>Remote backup: <a href="https://osf.io/9jk3e/">OSF</a></li><li>Description: RefSeq annotation in GTF format that has been remapped to use the same set of UCSC-style sequence identifiers used in the FASTA files. The annotation is NCBI Homo sapiens Updated Annotation Release 109.20190125 from 25 January 2019.</li><li>Recipe:<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/000/001/405/GCA_000001405.15_GRCh38/seqs_for_alignment_pipelines.ucsc_ids/GCA_000001405.15_GRCh38_full_analysis_set.refseq_annotation.gtf.gz</span><br><span class="line">mv GCA_000001405.15_GRCh38_full_analysis_set.refseq_annotation.gtf.gz refseq.ver109.20190125.annotation.gtf.gz</span><br></pre></td></tr></table></figure></li></ul><h4 id="Other-annotations"><a href="#Other-annotations" class="headerlink" title="Other annotations"></a>Other annotations</h4><h5 id="Repeat-Masker"><a href="#Repeat-Masker" class="headerlink" title="Repeat Masker"></a>Repeat Masker</h5><ul><li>File name: <code>rmsk.bed.gz</code> (MD5 checksum: <code>ae12aefbef9d4f5bc7695158a67d9a55</code>)</li><li>Local path: <em>&#x2F;References&#x2F;Annotations&#x2F;human&#x2F;hg38&#x2F;rmsk.bed.gz</em></li><li>Remote backup: <a href="https://osf.io/e7w3k/">OSF</a></li><li>Description: Repeat Masker from UCSC. The following fields were selected:<ul><li>genoName (Genomic sequence name)</li><li>genoStart (Start in genomic sequence)</li><li>genoEnd (End in genomic sequence)</li><li>strand (Relative orientation + or -)</li><li>repName (Name of repeat) </li><li>repFamily (Family of repeat).</li></ul></li><li>Recipe:<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget http://hgdownload.soe.ucsc.edu/goldenPath/hg38/database/rmsk.txt.gz</span><br><span class="line">gunzip rmsk.txt.gz</span><br><span class="line">gawk &#x27;OFS=&quot;\t&quot;&#123;print $6,$7,$8,$11,$13,$10&#125;&#x27; rmsk.txt | \</span><br><span class="line">    sort -k1,1 -k2,2n | \</span><br><span class="line">    bgzip &gt; rmsk.bed.gz</span><br></pre></td></tr></table></figure></li></ul><h2 id="Generic"><a href="#Generic" class="headerlink" title="Generic"></a>Generic</h2><h3 id="Sequences-1"><a href="#Sequences-1" class="headerlink" title="Sequences"></a>Sequences</h3><ul><li>Primary assembly: </li><li>rRNA: Human ribosomal DNA complete repeating unit, GenBank accession code: U13369.1 .</li></ul><h3 id="Annotations-1"><a href="#Annotations-1" class="headerlink" title="Annotations"></a>Annotations</h3><h4 id="Motif-databases-MEME"><a href="#Motif-databases-MEME" class="headerlink" title="Motif databases (MEME)"></a>Motif databases (MEME)</h4><ul><li>File name: <code>motif_databases.12.19.tgz</code> (MD5 checksum: <code>f5ffcaecc07570ee19dba20b82d7bd73</code>)</li><li>Local path: <em>&#x2F;References&#x2F;Annotations&#x2F;human&#x2F;generic&#x2F;motif_databases.12.19.tgz</em></li><li>Remote backup: <a href="https://osf.io/cktus/">OSF</a></li><li>Description: Motif databases for MEME suite (updated 28 Oct 2019).</li><li>Recipe:<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://alternate.meme-suite.org/meme-software/Databases/motifs/motif_databases.12.19.tgz</span><br></pre></td></tr></table></figure></li></ul><h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul><li>For all fasta files, 3 standard annotations will also be generated simultaneously:<ul><li><code>.fai</code>: index which allows for fast and random access to any sequences in the indexed fasta file. This index is generated with the following command:  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">samtools faidx input.fa</span><br></pre></td></tr></table></figure></li><li><code>.genome</code>: Table with two columns, specifying length of each chromosome.  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cut -f1,2 input.fa.fai &gt; size.genome</span><br></pre></td></tr></table></figure></li><li><code>.dict</code>:   <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java -jar picard.jar CreateSequenceDictionary \</span><br><span class="line">    R=input.fa \ </span><br><span class="line">    O=input.dict</span><br></pre></td></tr></table></figure></li></ul></li><li>There are two types of promoters in both <code>gencode.v24.segmented.tssup1kb.bed</code> and <code>gencode.v24.segmented.tssflanking1kb.bed </code>:<ul><li>Promoters for protein coding genes (denote as <code>promoter</code> in these files)</li><li>Promoters for non-protein coding genes (denote as <code>promoter(NP)</code>)</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Human&quot;&gt;&lt;a href=&quot;#Human&quot; class=&quot;headerlink&quot; title=&quot;Human&quot;&gt;&lt;/a&gt;Human&lt;/h1&gt;&lt;p&gt;Currently, there are two widely used releases GRCh38 (hg38</summary>
      
    
    
    
    <category term="posts" scheme="https://www.yaobio.com/posts/"/>
    
    
    <category term="resources" scheme="https://www.yaobio.com/tags/resources/"/>
    
  </entry>
  
  <entry>
    <title>Inhibition of DCLK1 down-regulates PD-L1 expression through Hippo pathway in human pancreatic cancer</title>
    <link href="https://www.yaobio.com/publication/inhibition-of-dclk1-down-regulates-pd-l1-expression-through-hippo-pathway-in-human-pancreatic-cancer/"/>
    <id>https://www.yaobio.com/publication/inhibition-of-dclk1-down-regulates-pd-l1-expression-through-hippo-pathway-in-human-pancreatic-cancer/</id>
    <published>2019-12-05T14:40:14.000Z</published>
    <updated>2025-04-23T04:03:22.947Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Immunotherapy is one of the most promising strategies for cancer, compared with traditional treatments. As one of the key emerging immunotherapies, anti-PD-1&#x2F;PD-L1 treatment has brought survival benefits to many advanced cancer patients. However, in pancreatic cancer, immunotherapy-based approaches have not achieved a favorable clinical effect because of mismatch repair deficiencies. Therefore, the majority of pancreatic tumors are regarded as immune-quiescent tumors and non-responsive to single-checkpoint blockade therapies. Many preclinical and clinical studies suggest that it is still important to clarify the regulatory mechanism of the PD-1&#x2F; PD-L1 pathway in pancreatic cancer. As a marker of cancer stem cells, DCLK1 has been found to play an important role in the occurrence and development of a plethora of human cancers. Recent researches have revealed that DCLK1 is closely related to EMT process of tumor cells, meanwhile, it could also be used as a biomarker in gastrointestinal tumors to predict the prognoses of patients. However, the role that DCLK1 plays in the immune regulation of tumor microenvironments remains unknown. Therefore, we sought to understand if DCLK1 could positively regulate the expression of PD-L1 in pancreatic cancer cells. Furthermore, we examined if DCLK1 highly correlated with the Hippo pathway through TCGA database analysis. We found that DCLK1 helped regulate the level of PD-L1 expression by affecting the corresponding expression level of yes-associated protein in the Hippo pathway. Collectively, our study identifies DCLK1 as an important regulator of PD-L1 expression in pancreatic tumor and highlights a central role of DCLK1 in the regulation of tumor immunity.</p><h2 id="Accepted-manuscript"><a href="#Accepted-manuscript" class="headerlink" title="Accepted manuscript"></a>Accepted manuscript</h2><embed src="/assets/archives/2019_DCLK1_PAAD.pdf" width="100%" height="1000" type="application/pdf">]]></content>
    
    
    <summary type="html">&lt;p&gt;Immunotherapy is one of the most promising strategies for cancer, compared with traditional treatments. 
As one of the key emerging immunotherapies, anti-PD-1&amp;#x2F;PD-L1 treatment has brought survival benefits to 
many advanced cancer patients. However, in pancreatic cancer, immunotherapy-based approaches have not 
achieved a favorable clinical effect because of mismatch repair deficiencies. Therefore, the majority 
of pancreatic tumors are regarded as immune-quiescent tumors and non-responsive to single-checkpoint 
blockade therapies. Many preclinical and clinical studies suggest that it is still important to clarify 
the regulatory mechanism of the PD-1&amp;#x2F; PD-L1 pathway in pancreatic cancer. As a marker of cancer stem cells, 
DCLK1 has been found to play an important role in the occurrence and development of a plethora of human 
cancers. Recent researches have revealed that DCLK1 is closely related to EMT process of tumor cells, meanwhile, 
it could also be used as a biomarker in gastrointestinal tumors to predict the prognoses of patients. 
However, the role that DCLK1 plays in the immune regulation of tumor microenvironments remains unknown. 
Therefore, we sought to understand if DCLK1 could positively regulate the expression of PD-L1 in pancreatic 
cancer cells. Furthermore, we examined if DCLK1 highly correlated with the Hippo pathway through TCGA database 
analysis. We found that DCLK1 helped regulate the level of PD-L1 expression by affecting the corresponding 
expression level of yes-associated protein in the Hippo pathway. Collectively, our study identifies DCLK1 as 
an important regulator of PD-L1 expression in pancreatic tumor and highlights a central role of DCLK1 in the 
regulation of tumor immunity.&lt;/p&gt;</summary>
    
    
    
    <category term="publication" scheme="https://www.yaobio.com/publication/"/>
    
    
  </entry>
  
  <entry>
    <title>bioSyntax</title>
    <link href="https://www.yaobio.com/tools/biosyntax/"/>
    <id>https://www.yaobio.com/tools/biosyntax/</id>
    <published>2019-11-22T11:40:40.000Z</published>
    <updated>2025-04-23T04:03:22.957Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>If you are interested in the detailed methodology, please refer to our manuscript, <em><a href="/publication/biosyntax-syntax-highlighting-for-computational-biology/" title="bioSyntax: syntax highlighting for computational biology">bioSyntax: syntax highlighting for computational biology</a></em>, for more information.</p></blockquote><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>bioSyntax is a tool designed to simplify the inspection of biological sequences, regions, and alignments. It is compatible with multiple text editors such as <code>vim</code>, <code>VS Code</code>, <code>sublime</code>, <code>less</code>, and <code>gedit</code>.</p><p>It provides syntax highlighting for various file formats including FASTA, FASTQ, CWL, BED, GTF, PDB, PML, SAM, and VCF.</p><p>This tool is a collaboration between Artem Babaian (lead developer), Anicet Ebou, Alyssa Fegen, Ho Yin Kam, German E. Novakovsky, Jasper Wong, Dylan Aïssi, and me.</p><h2 id="Availability"><a href="#Availability" class="headerlink" title="Availability"></a>Availability</h2><p>bioSyntax can be accessed through the accompany package control tools for most of the text editors. For example, if you are a <code>Visual Studio Code</code> user, you can install bioSyntax via <a href="https://marketplace.visualstudio.com/items?itemName=reageyao.biosyntax">Visual Studio Marketplace</a>.</p><h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><div id="player" style="width: 50%; margin:auto;"></div><p>Source: <a href="https://asciinema.org/a/153567">asciinema</a></p><link rel="stylesheet" type="text/css" href="/css/asciinema-player.css" /><script src="/js/asciinema-player.min.js"></script><script>    AsciinemaPlayer.create(      '/tools/biosyntax/153567.json',      document.getElementById('player'),      { cols: 92, rows: 33 , poster: 'npt:0:35'}    );</script>]]></content>
    
    
    <summary type="html">&lt;p&gt;bioSyntax is a tool designed to simplify the inspection of biological sequences, regions, and alignments. 
It is compatible with multiple text editors such as &lt;code&gt;vim&lt;/code&gt;, &lt;code&gt;VS Code&lt;/code&gt;, &lt;code&gt;sublime&lt;/code&gt;, &lt;code&gt;less&lt;/code&gt;, and &lt;code&gt;gedit&lt;/code&gt;.&lt;/p&gt;</summary>
    
    
    
    <category term="tools" scheme="https://www.yaobio.com/tools/"/>
    
    
  </entry>
  
</feed>
